<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 16 Generalised linear models | Advanced Quantitative methods</title>
  <meta name="description" content="Chapter 16 Generalised linear models | Advanced Quantitative methods">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 16 Generalised linear models | Advanced Quantitative methods" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 16 Generalised linear models | Advanced Quantitative methods" />
  
  
  

<meta name="author" content="Duncan Golicher">


<meta name="date" content="2019-10-23">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="factorial-designs.html">
<link rel="next" href="modelling-with-multiple-variables.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.4/datatables.js"></script>
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.16/js/jquery.dataTables.min.js"></script>
<script src="libs/jszip-1.10.16/jszip.min.js"></script>
<link href="libs/dt-ext-buttons-1.10.16/css/buttons.dataTables.min.css" rel="stylesheet" />
<script src="libs/dt-ext-buttons-1.10.16/js/dataTables.buttons.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.flash.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.html5.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.colVis.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.print.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.2/leaflet.js"></script>
<script src="libs/leaflet-providers-1.1.17/leaflet-providers.js"></script>
<script src="libs/leaflet-providers-plugin-2.0.2/leaflet-providers-plugin.js"></script>
<link href="libs/HomeButton-0.0.1/home-button.css" rel="stylesheet" />
<script src="libs/HomeButton-0.0.1/home-button.js"></script>
<script src="libs/HomeButton-0.0.1/easy-button-src.min.js"></script>
<link href="libs/PopupTable-0.0.1/popup.css" rel="stylesheet" />
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>
<link href="libs/lfx-fullscreen-1.0.2/lfx-fullscreen-prod.css" rel="stylesheet" />
<script src="libs/lfx-fullscreen-1.0.2/lfx-fullscreen-prod.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Quantitative Methods</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#the-new-statistics"><i class="fa fa-check"></i><b>1.1</b> The new statistics</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#statistical-models-vs-statistical-tests"><i class="fa fa-check"></i><b>1.2</b> Statistical models vs statistical tests</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#bayesian-vs-frequentist-approaches-to-inference"><i class="fa fa-check"></i><b>1.3</b> Bayesian vs frequentist approaches to inference</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#using-p-values-with-discretion"><i class="fa fa-check"></i><b>1.4</b> Using p-values with discretion</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#common-pitfalls"><i class="fa fa-check"></i><b>1.5</b> Common pitfalls</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html"><i class="fa fa-check"></i><b>2</b> Using the RStudio server</a><ul>
<li class="chapter" data-level="2.1" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html#introduction-1"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html#getting-started-with-the-rstudio-server"><i class="fa fa-check"></i><b>2.2</b> Getting started with the RStudio server</a><ul>
<li class="chapter" data-level="2.2.1" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html#log-into-the-rstudio-server"><i class="fa fa-check"></i><b>2.2.1</b> Log into the RStudio server</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html#rstudio-server-concepts"><i class="fa fa-check"></i><b>2.3</b> RStudio server concepts</a></li>
<li class="chapter" data-level="2.4" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html#finding-your-way-around-the-interface"><i class="fa fa-check"></i><b>2.4</b> Finding your way around the interface</a></li>
<li class="chapter" data-level="2.5" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html#using-projects-in-rstudio"><i class="fa fa-check"></i><b>2.5</b> Using projects in RStudio</a></li>
<li class="chapter" data-level="2.6" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html#uploading-data"><i class="fa fa-check"></i><b>2.6</b> Uploading data</a></li>
<li class="chapter" data-level="2.7" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html#working-with-markdown-documents."><i class="fa fa-check"></i><b>2.7</b> Working with markdown documents.</a></li>
<li class="chapter" data-level="2.8" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html#forming-a-markdown-document."><i class="fa fa-check"></i><b>2.8</b> Forming a markdown document.</a></li>
<li class="chapter" data-level="2.9" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html#reading-in-your-data"><i class="fa fa-check"></i><b>2.9</b> Reading in your data</a></li>
<li class="chapter" data-level="2.10" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html#adding-analysis-chunks"><i class="fa fa-check"></i><b>2.10</b> Adding analysis chunks</a></li>
<li class="chapter" data-level="2.11" data-path="using-the-rstudio-server.html"><a href="using-the-rstudio-server.html#compiling-a-report"><i class="fa fa-check"></i><b>2.11</b> Compiling a report</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html"><i class="fa fa-check"></i><b>3</b> Reading data into R from a web site</a><ul>
<li class="chapter" data-level="3.1" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#introduction-2"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#example.-reading-data-from-the-met-office-historical-data-site"><i class="fa fa-check"></i><b>3.2</b> Example. Reading data from the met office historical data site</a></li>
<li class="chapter" data-level="3.3" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#reading-the-raw-file"><i class="fa fa-check"></i><b>3.3</b> Reading the raw file</a></li>
<li class="chapter" data-level="3.4" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#reading-the-data-to-a-data-frame"><i class="fa fa-check"></i><b>3.4</b> Reading the data to a data frame</a></li>
<li class="chapter" data-level="3.5" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#adding-names"><i class="fa fa-check"></i><b>3.5</b> Adding names</a></li>
<li class="chapter" data-level="3.6" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#cleaning-the-columns"><i class="fa fa-check"></i><b>3.6</b> Cleaning the columns</a></li>
<li class="chapter" data-level="3.7" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#making-a-date-column"><i class="fa fa-check"></i><b>3.7</b> Making a date column</a></li>
<li class="chapter" data-level="3.8" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#looking-at-the-raw-data"><i class="fa fa-check"></i><b>3.8</b> Looking at the raw data</a></li>
<li class="chapter" data-level="3.9" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#plotting-the-data"><i class="fa fa-check"></i><b>3.9</b> Plotting the data</a></li>
<li class="chapter" data-level="3.10" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#long-to-wide-conversion"><i class="fa fa-check"></i><b>3.10</b> Long to wide conversion</a></li>
<li class="chapter" data-level="3.11" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#disadvantages-of-the-wide-format"><i class="fa fa-check"></i><b>3.11</b> Disadvantages of the wide format</a></li>
<li class="chapter" data-level="3.12" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#using-dplyr-to-summarise"><i class="fa fa-check"></i><b>3.12</b> Using dplyr to summarise</a></li>
<li class="chapter" data-level="3.13" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#repeating-the-operation"><i class="fa fa-check"></i><b>3.13</b> Repeating the operation</a></li>
<li class="chapter" data-level="3.14" data-path="reading-data-into-r-from-a-web-site.html"><a href="reading-data-into-r-from-a-web-site.html#get-lattitude-and-longitude"><i class="fa fa-check"></i><b>3.14</b> Get lattitude and Longitude</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="using-dplyr.html"><a href="using-dplyr.html"><i class="fa fa-check"></i><b>4</b> Using dplyr</a><ul>
<li class="chapter" data-level="4.1" data-path="using-dplyr.html"><a href="using-dplyr.html#loading-the-saved-data"><i class="fa fa-check"></i><b>4.1</b> Loading the saved data</a></li>
<li class="chapter" data-level="4.2" data-path="using-dplyr.html"><a href="using-dplyr.html#using-dplyr-1"><i class="fa fa-check"></i><b>4.2</b> Using dplyr</a></li>
<li class="chapter" data-level="4.3" data-path="using-dplyr.html"><a href="using-dplyr.html#plotting"><i class="fa fa-check"></i><b>4.3</b> Plotting</a></li>
<li class="chapter" data-level="4.4" data-path="using-dplyr.html"><a href="using-dplyr.html#another-example"><i class="fa fa-check"></i><b>4.4</b> Another example</a></li>
<li class="chapter" data-level="4.5" data-path="using-dplyr.html"><a href="using-dplyr.html#the-in-filter"><i class="fa fa-check"></i><b>4.5</b> The %in% filter</a></li>
<li class="chapter" data-level="4.6" data-path="using-dplyr.html"><a href="using-dplyr.html#aggregating-years-to-decades"><i class="fa fa-check"></i><b>4.6</b> Aggregating years to decades</a></li>
<li class="chapter" data-level="4.7" data-path="using-dplyr.html"><a href="using-dplyr.html#exercise"><i class="fa fa-check"></i><b>4.7</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="r-programming.html"><a href="r-programming.html"><i class="fa fa-check"></i><b>5</b> R programming</a><ul>
<li class="chapter" data-level="5.1" data-path="r-programming.html"><a href="r-programming.html#using-base-r-to-simulate-data"><i class="fa fa-check"></i><b>5.1</b> Using base R to simulate data</a><ul>
<li class="chapter" data-level="5.1.1" data-path="r-programming.html"><a href="r-programming.html#some-very-simple-r-commands"><i class="fa fa-check"></i><b>5.1.1</b> Some very simple R commands</a></li>
<li class="chapter" data-level="5.1.2" data-path="r-programming.html"><a href="r-programming.html#data-structures"><i class="fa fa-check"></i><b>5.1.2</b> Data structures</a></li>
<li class="chapter" data-level="5.1.3" data-path="r-programming.html"><a href="r-programming.html#generating-sequences-of-numbers-in-r"><i class="fa fa-check"></i><b>5.1.3</b> Generating sequences of numbers in R</a></li>
<li class="chapter" data-level="5.1.4" data-path="r-programming.html"><a href="r-programming.html#logical-vectors-and-subsetting"><i class="fa fa-check"></i><b>5.1.4</b> Logical vectors and subsetting</a></li>
<li class="chapter" data-level="5.1.5" data-path="r-programming.html"><a href="r-programming.html#simulating-from-known-distributions"><i class="fa fa-check"></i><b>5.1.5</b> Simulating from known distributions</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="r-programming.html"><a href="r-programming.html#a-simple-simulated-data-set"><i class="fa fa-check"></i><b>5.2</b> A simple simulated data set</a><ul>
<li class="chapter" data-level="5.2.1" data-path="r-programming.html"><a href="r-programming.html#saving-and-loading-data-frames"><i class="fa fa-check"></i><b>5.2.1</b> Saving and loading data frames</a></li>
<li class="chapter" data-level="5.2.2" data-path="r-programming.html"><a href="r-programming.html#histogram-of-simulated-data"><i class="fa fa-check"></i><b>5.2.2</b> Histogram of simulated data</a></li>
<li class="chapter" data-level="5.2.3" data-path="r-programming.html"><a href="r-programming.html#boxplot-using-ggplot"><i class="fa fa-check"></i><b>5.2.3</b> Boxplot using ggplot</a></li>
<li class="chapter" data-level="5.2.4" data-path="r-programming.html"><a href="r-programming.html#confidence-interval-plot"><i class="fa fa-check"></i><b>5.2.4</b> Confidence interval plot</a></li>
<li class="chapter" data-level="5.2.5" data-path="r-programming.html"><a href="r-programming.html#summarising-using-dplyr"><i class="fa fa-check"></i><b>5.2.5</b> Summarising using dplyr</a></li>
<li class="chapter" data-level="5.2.6" data-path="r-programming.html"><a href="r-programming.html#statistical-test"><i class="fa fa-check"></i><b>5.2.6</b> Statistical test</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="r-programming.html"><a href="r-programming.html#simulating-a-regression"><i class="fa fa-check"></i><b>5.3</b> Simulating a regression</a><ul>
<li class="chapter" data-level="5.3.1" data-path="r-programming.html"><a href="r-programming.html#simulating-likert-responses"><i class="fa fa-check"></i><b>5.3.1</b> Simulating Likert responses</a></li>
<li class="chapter" data-level="5.3.2" data-path="r-programming.html"><a href="r-programming.html#simulating-spatially-explicit-data"><i class="fa fa-check"></i><b>5.3.2</b> Simulating spatially explicit data</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="r-programming.html"><a href="r-programming.html#exercises"><i class="fa fa-check"></i><b>5.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html"><i class="fa fa-check"></i><b>6</b> Introduction to statistical modelling</a><ul>
<li class="chapter" data-level="6.1" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#what-is-a-statistical-model"><i class="fa fa-check"></i><b>6.1</b> What is a statistical model?</a><ul>
<li class="chapter" data-level="6.1.1" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#uses-of-models"><i class="fa fa-check"></i><b>6.1.1</b> Uses of models</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#the-general-linear-model"><i class="fa fa-check"></i><b>6.2</b> The general linear model</a></li>
<li class="chapter" data-level="6.3" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#regression"><i class="fa fa-check"></i><b>6.3</b> Regression</a><ul>
<li class="chapter" data-level="6.3.1" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#theory"><i class="fa fa-check"></i><b>6.3.1</b> Theory</a></li>
<li class="chapter" data-level="6.3.2" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#example"><i class="fa fa-check"></i><b>6.3.2</b> Example</a></li>
<li class="chapter" data-level="6.3.3" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#confidence-intervals"><i class="fa fa-check"></i><b>6.3.3</b> Confidence intervals</a></li>
<li class="chapter" data-level="6.3.4" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#prediction-1"><i class="fa fa-check"></i><b>6.3.4</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#using-ggplot2-for-confidence-intervals."><i class="fa fa-check"></i><b>6.4</b> Using ggplot2 for confidence intervals.</a><ul>
<li class="chapter" data-level="6.4.1" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#prediction-intervals"><i class="fa fa-check"></i><b>6.4.1</b> Prediction intervals</a></li>
<li class="chapter" data-level="6.4.2" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#diagnostics"><i class="fa fa-check"></i><b>6.4.2</b> Diagnostics</a></li>
<li class="chapter" data-level="6.4.3" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#lack-of-independence"><i class="fa fa-check"></i><b>6.4.3</b> Lack of independence</a></li>
<li class="chapter" data-level="6.4.4" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#violations-of-assumptions"><i class="fa fa-check"></i><b>6.4.4</b> Violations of assumptions</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#exercises-1"><i class="fa fa-check"></i><b>6.5</b> Exercises</a></li>
<li class="chapter" data-level="6.6" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#some-data-wrangling"><i class="fa fa-check"></i><b>6.6</b> Some “data wrangling”</a></li>
<li class="chapter" data-level="6.7" data-path="introduction-to-statistical-modelling.html"><a href="introduction-to-statistical-modelling.html#one-way-to-run-multiple-analyses"><i class="fa fa-check"></i><b>6.7</b> One way to run multiple analyses</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html"><i class="fa fa-check"></i><b>7</b> Some theory on the general linear model</a><ul>
<li class="chapter" data-level="7.1" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#calculating-the-sum-of-squares"><i class="fa fa-check"></i><b>7.1</b> Calculating the sum of squares</a><ul>
<li class="chapter" data-level="7.1.1" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#regression-1"><i class="fa fa-check"></i><b>7.1.1</b> Regression</a></li>
<li class="chapter" data-level="7.1.2" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#residuals"><i class="fa fa-check"></i><b>7.1.2</b> Residuals</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#where-does-r-squared-coefficient-of-determination-come-from"><i class="fa fa-check"></i><b>7.2</b> Where does R squared (coefficient of determination) come from?</a></li>
<li class="chapter" data-level="7.3" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#model-assumptions"><i class="fa fa-check"></i><b>7.3</b> Model assumptions</a></li>
<li class="chapter" data-level="7.4" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#some-practice-using-linear-models"><i class="fa fa-check"></i><b>7.4</b> Some practice using linear models</a></li>
<li class="chapter" data-level="7.5" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#one-way-anova"><i class="fa fa-check"></i><b>7.5</b> One way Anova</a><ul>
<li class="chapter" data-level="7.5.1" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#diagnostics-1"><i class="fa fa-check"></i><b>7.5.1</b> Diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#statistical-inference"><i class="fa fa-check"></i><b>7.6</b> Statistical inference</a></li>
<li class="chapter" data-level="7.7" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#fitting-a-linear-model"><i class="fa fa-check"></i><b>7.7</b> Fitting a linear model</a></li>
<li class="chapter" data-level="7.8" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#diagnostics-2"><i class="fa fa-check"></i><b>7.8</b> Diagnostics</a></li>
<li class="chapter" data-level="7.9" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#treatment-contrasts-using-summary"><i class="fa fa-check"></i><b>7.9</b> Treatment contrasts using summary</a></li>
<li class="chapter" data-level="7.10" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#changing-the-reference-leval"><i class="fa fa-check"></i><b>7.10</b> Changing the reference leval</a></li>
<li class="chapter" data-level="7.11" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#multiple-comparisons"><i class="fa fa-check"></i><b>7.11</b> Multiple comparisons</a></li>
<li class="chapter" data-level="7.12" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#scale-location-plot"><i class="fa fa-check"></i><b>7.12</b> Scale location plot</a></li>
<li class="chapter" data-level="7.13" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#example-of-heterogeniety"><i class="fa fa-check"></i><b>7.13</b> Example of heterogeniety</a></li>
<li class="chapter" data-level="7.14" data-path="some-theory-on-the-general-linear-model.html"><a href="some-theory-on-the-general-linear-model.html#exercises-2"><i class="fa fa-check"></i><b>7.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html"><i class="fa fa-check"></i><b>8</b> One way ANOVA</a><ul>
<li class="chapter" data-level="8.1" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#introduction-3"><i class="fa fa-check"></i><b>8.1</b> Introduction</a><ul>
<li class="chapter" data-level="8.1.1" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#multiple-comparisons-1"><i class="fa fa-check"></i><b>8.1.1</b> Multiple comparisons</a></li>
<li class="chapter" data-level="8.1.2" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#visualising-between-group-variation-using-boxplots"><i class="fa fa-check"></i><b>8.1.2</b> Visualising between group variation using boxplots</a></li>
<li class="chapter" data-level="8.1.3" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#boxplot-statistics"><i class="fa fa-check"></i><b>8.1.3</b> Boxplot statistics</a></li>
<li class="chapter" data-level="8.1.4" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#plotting-confidence-intervals-for-each-group"><i class="fa fa-check"></i><b>8.1.4</b> Plotting confidence intervals for each group</a></li>
<li class="chapter" data-level="8.1.5" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#fitting-a-model"><i class="fa fa-check"></i><b>8.1.5</b> Fitting a model</a></li>
<li class="chapter" data-level="8.1.6" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#the-f-ratio-and-degrees-of-freedom"><i class="fa fa-check"></i><b>8.1.6</b> The F ratio and degrees of freedom</a></li>
<li class="chapter" data-level="8.1.7" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#homogeneity-of-variance-1"><i class="fa fa-check"></i><b>8.1.7</b> Homogeneity of variance</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#alternative-to-the-one-way-test"><i class="fa fa-check"></i><b>8.2</b> Alternative to the one way test</a><ul>
<li class="chapter" data-level="8.2.1" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#determining-where-the-differences-lie"><i class="fa fa-check"></i><b>8.2.1</b> Determining where the differences lie</a></li>
<li class="chapter" data-level="8.2.2" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#bonferoni-corrections"><i class="fa fa-check"></i><b>8.2.2</b> Bonferoni corrections</a></li>
<li class="chapter" data-level="8.2.3" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#tukeys-honest-significant-difference"><i class="fa fa-check"></i><b>8.2.3</b> Tukey’s honest significant difference</a></li>
<li class="chapter" data-level="8.2.4" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#the-kruskal-wallace-non-parametric-test."><i class="fa fa-check"></i><b>8.2.4</b> The Kruskal Wallace non parametric test.</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#power-analysis"><i class="fa fa-check"></i><b>8.3</b> Power analysis</a></li>
<li class="chapter" data-level="8.4" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#bayesian-methods"><i class="fa fa-check"></i><b>8.4</b> Bayesian methods</a></li>
<li class="chapter" data-level="8.5" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#the-mussels-data-set"><i class="fa fa-check"></i><b>8.5</b> The mussels data set</a><ul>
<li class="chapter" data-level="8.5.1" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#heterogeneity-of-variance-and-unbalanced-sample-sizes"><i class="fa fa-check"></i><b>8.5.1</b> Heterogeneity of variance and unbalanced sample sizes</a></li>
<li class="chapter" data-level="8.5.2" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#confidence-intervals-1"><i class="fa fa-check"></i><b>8.5.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="8.5.3" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#conventional-one-way-anova-and-multiple-comparisons"><i class="fa fa-check"></i><b>8.5.3</b> Conventional One way ANOVA and multiple comparisons</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#treatment-contrasts"><i class="fa fa-check"></i><b>8.6</b> Treatment contrasts</a></li>
<li class="chapter" data-level="8.7" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#multiple-comparisons-2"><i class="fa fa-check"></i><b>8.7</b> Multiple comparisons</a></li>
<li class="chapter" data-level="8.8" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#sum-to-zero-contrasts"><i class="fa fa-check"></i><b>8.8</b> Sum to zero contrasts</a><ul>
<li class="chapter" data-level="8.8.1" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#heterogenity-of-variance"><i class="fa fa-check"></i><b>8.8.1</b> Heterogenity of variance</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#bayesian-credible-inference"><i class="fa fa-check"></i><b>8.9</b> Bayesian credible inference</a><ul>
<li class="chapter" data-level="8.9.1" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#pooled-variance-model-using-jags"><i class="fa fa-check"></i><b>8.9.1</b> Pooled variance model using JAGS</a></li>
</ul></li>
<li class="chapter" data-level="8.10" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#independent-variances-model"><i class="fa fa-check"></i><b>8.10</b> Independent variances model</a></li>
<li class="chapter" data-level="8.11" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#random-effects-model"><i class="fa fa-check"></i><b>8.11</b> Random effects model</a></li>
<li class="chapter" data-level="8.12" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#extensions-and-conclusion"><i class="fa fa-check"></i><b>8.12</b> Extensions and conclusion</a></li>
<li class="chapter" data-level="8.13" data-path="one-way-anova-1.html"><a href="one-way-anova-1.html#references"><i class="fa fa-check"></i><b>8.13</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="fitting-curves-to-data.html"><a href="fitting-curves-to-data.html"><i class="fa fa-check"></i><b>9</b> Fitting curves to data</a><ul>
<li class="chapter" data-level="9.1" data-path="fitting-curves-to-data.html"><a href="fitting-curves-to-data.html#data-exploration"><i class="fa fa-check"></i><b>9.1</b> Data exploration</a><ul>
<li class="chapter" data-level="9.1.1" data-path="fitting-curves-to-data.html"><a href="fitting-curves-to-data.html#visualisation"><i class="fa fa-check"></i><b>9.1.1</b> Visualisation</a></li>
<li class="chapter" data-level="9.1.2" data-path="fitting-curves-to-data.html"><a href="fitting-curves-to-data.html#t-values-and-significance-in-summary-output"><i class="fa fa-check"></i><b>9.1.2</b> T values and significance in summary output</a></li>
<li class="chapter" data-level="9.1.3" data-path="fitting-curves-to-data.html"><a href="fitting-curves-to-data.html#testing-for-curvilearity"><i class="fa fa-check"></i><b>9.1.3</b> Testing for curvilearity</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="fitting-curves-to-data.html"><a href="fitting-curves-to-data.html#polynomials"><i class="fa fa-check"></i><b>9.2</b> Polynomials</a></li>
<li class="chapter" data-level="9.3" data-path="fitting-curves-to-data.html"><a href="fitting-curves-to-data.html#splines"><i class="fa fa-check"></i><b>9.3</b> Splines</a></li>
<li class="chapter" data-level="9.4" data-path="fitting-curves-to-data.html"><a href="fitting-curves-to-data.html#complex-shapes"><i class="fa fa-check"></i><b>9.4</b> Complex shapes</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>10</b> Non-linear models</a><ul>
<li class="chapter" data-level="10.1" data-path="non-linear-models.html"><a href="non-linear-models.html#fitting-a-rectangular-hyperbola"><i class="fa fa-check"></i><b>10.1</b> Fitting a rectangular hyperbola</a></li>
<li class="chapter" data-level="10.2" data-path="non-linear-models.html"><a href="non-linear-models.html#real-data"><i class="fa fa-check"></i><b>10.2</b> Real data</a><ul>
<li class="chapter" data-level="10.2.1" data-path="non-linear-models.html"><a href="non-linear-models.html#calculating-the-r-squared"><i class="fa fa-check"></i><b>10.2.1</b> Calculating the R squared</a></li>
<li class="chapter" data-level="10.2.2" data-path="non-linear-models.html"><a href="non-linear-models.html#including-the-vigilance-term"><i class="fa fa-check"></i><b>10.2.2</b> Including the vigilance term</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="non-linear-models.html"><a href="non-linear-models.html#quantile-regression"><i class="fa fa-check"></i><b>10.3</b> Quantile regression</a></li>
<li class="chapter" data-level="10.4" data-path="non-linear-models.html"><a href="non-linear-models.html#summary"><i class="fa fa-check"></i><b>10.4</b> Summary</a></li>
<li class="chapter" data-level="10.5" data-path="non-linear-models.html"><a href="non-linear-models.html#exercise-1"><i class="fa fa-check"></i><b>10.5</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html"><i class="fa fa-check"></i><b>11</b> Analysis of covariance, nested data and mixed effects</a><ul>
<li class="chapter" data-level="11.1" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#introduction-4"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#whale-teeth-and-isotope-ratios"><i class="fa fa-check"></i><b>11.2</b> Whale teeth and isotope ratios</a><ul>
<li class="chapter" data-level="11.2.1" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#mobys-tooth"><i class="fa fa-check"></i><b>11.2.1</b> Moby’s tooth</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#plotting-the-data-1"><i class="fa fa-check"></i><b>11.3</b> Plotting the data</a></li>
<li class="chapter" data-level="11.4" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#fitting-a-regression"><i class="fa fa-check"></i><b>11.4</b> Fitting a regression</a><ul>
<li class="chapter" data-level="11.4.1" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#diagnostics-3"><i class="fa fa-check"></i><b>11.4.1</b> Diagnostics</a></li>
<li class="chapter" data-level="11.4.2" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#testing-for-serial-correlation"><i class="fa fa-check"></i><b>11.4.2</b> Testing for serial correlation</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#interpreting-the-results"><i class="fa fa-check"></i><b>11.5</b> Interpreting the results</a></li>
<li class="chapter" data-level="11.6" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#exercise-2"><i class="fa fa-check"></i><b>11.6</b> Exercise</a></li>
<li class="chapter" data-level="11.7" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#finding-a-general-pattern"><i class="fa fa-check"></i><b>11.7</b> Finding a general pattern</a></li>
<li class="chapter" data-level="11.8" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#analysis-of-covariance"><i class="fa fa-check"></i><b>11.8</b> Analysis of covariance</a><ul>
<li class="chapter" data-level="11.8.1" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#more-about-interactions"><i class="fa fa-check"></i><b>11.8.1</b> More about interactions</a></li>
<li class="chapter" data-level="11.8.2" data-path="analysis-of-covariance-nested-data-and-mixed-effects.html"><a href="analysis-of-covariance-nested-data-and-mixed-effects.html#plotting-the-model"><i class="fa fa-check"></i><b>11.8.2</b> Plotting the model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="introducing-mixed-effects-modelling.html"><a href="introducing-mixed-effects-modelling.html"><i class="fa fa-check"></i><b>12</b> Introducing mixed effects modelling</a><ul>
<li class="chapter" data-level="12.1" data-path="introducing-mixed-effects-modelling.html"><a href="introducing-mixed-effects-modelling.html#using-the-nlme-package"><i class="fa fa-check"></i><b>12.1</b> Using the nlme package</a><ul>
<li class="chapter" data-level="12.1.1" data-path="introducing-mixed-effects-modelling.html"><a href="introducing-mixed-effects-modelling.html#intercept-only-model"><i class="fa fa-check"></i><b>12.1.1</b> Intercept only model</a></li>
<li class="chapter" data-level="12.1.2" data-path="introducing-mixed-effects-modelling.html"><a href="introducing-mixed-effects-modelling.html#random-slopes-model"><i class="fa fa-check"></i><b>12.1.2</b> Random slopes model</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="introducing-mixed-effects-modelling.html"><a href="introducing-mixed-effects-modelling.html#using-the-package-lme4"><i class="fa fa-check"></i><b>12.2</b> Using the package lme4</a><ul>
<li class="chapter" data-level="12.2.1" data-path="introducing-mixed-effects-modelling.html"><a href="introducing-mixed-effects-modelling.html#profile-confidence-intervals"><i class="fa fa-check"></i><b>12.2.1</b> Profile confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="introducing-mixed-effects-modelling.html"><a href="introducing-mixed-effects-modelling.html#ggplots-from-lme-output"><i class="fa fa-check"></i><b>12.3</b> Ggplots from lme output</a></li>
<li class="chapter" data-level="12.4" data-path="introducing-mixed-effects-modelling.html"><a href="introducing-mixed-effects-modelling.html#mixed-effect-gamm-models"><i class="fa fa-check"></i><b>12.4</b> Mixed effect gamm models</a></li>
<li class="chapter" data-level="12.5" data-path="introducing-mixed-effects-modelling.html"><a href="introducing-mixed-effects-modelling.html#summary-1"><i class="fa fa-check"></i><b>12.5</b> Summary</a><ul>
<li class="chapter" data-level="12.5.1" data-path="introducing-mixed-effects-modelling.html"><a href="introducing-mixed-effects-modelling.html#exercises-3"><i class="fa fa-check"></i><b>12.5.1</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html"><i class="fa fa-check"></i><b>13</b> Design and analysis of experiments part 1</a><ul>
<li class="chapter" data-level="13.1" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#introduction-5"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#basic-concepts-of-experimental-design"><i class="fa fa-check"></i><b>13.2</b> Basic concepts of experimental design</a><ul>
<li class="chapter" data-level="13.2.1" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#replication"><i class="fa fa-check"></i><b>13.2.1</b> 1. Replication</a></li>
<li class="chapter" data-level="13.2.2" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#treatment-levels"><i class="fa fa-check"></i><b>13.2.2</b> 2. Treatment levels</a></li>
<li class="chapter" data-level="13.2.3" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#randomisation"><i class="fa fa-check"></i><b>13.2.3</b> 3. Randomisation</a></li>
<li class="chapter" data-level="13.2.4" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#interactions"><i class="fa fa-check"></i><b>13.2.4</b> 4. Interactions</a></li>
<li class="chapter" data-level="13.2.5" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#fixed-and-random-effects"><i class="fa fa-check"></i><b>13.2.5</b> 5. Fixed and random effects</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#types-of-design"><i class="fa fa-check"></i><b>13.3</b> Types of design</a><ul>
<li class="chapter" data-level="13.3.1" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#completely-randomised-design"><i class="fa fa-check"></i><b>13.3.1</b> Completely randomised design</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#visualising-the-data"><i class="fa fa-check"></i><b>13.4</b> Visualising the data</a><ul>
<li class="chapter" data-level="13.4.1" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#comparisons"><i class="fa fa-check"></i><b>13.4.1</b> Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#completely-randomised-design-with-subsampling"><i class="fa fa-check"></i><b>13.5</b> Completely randomised design with subsampling</a><ul>
<li class="chapter" data-level="13.5.1" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#wrong-analyisis-for-the-subsampling"><i class="fa fa-check"></i><b>13.5.1</b> Wrong analyisis for the subsampling</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#randomized-complete-block-design"><i class="fa fa-check"></i><b>13.6</b> Randomized Complete Block Design</a><ul>
<li class="chapter" data-level="13.6.1" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#wrong-analysis-ignoring-the-effect-of-block"><i class="fa fa-check"></i><b>13.6.1</b> Wrong analysis ignoring the effect of block</a></li>
<li class="chapter" data-level="13.6.2" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#treating-block-as-a-random-effect"><i class="fa fa-check"></i><b>13.6.2</b> Treating block as a random effect</a></li>
<li class="chapter" data-level="13.6.3" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#treating-block-as-a-fixed-effect"><i class="fa fa-check"></i><b>13.6.3</b> Treating block as a fixed effect</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#illustation-of-how-block-effects-work"><i class="fa fa-check"></i><b>13.7</b> Illustation of how block effects work</a></li>
<li class="chapter" data-level="13.8" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#an-observational-example-of-sub-sampling"><i class="fa fa-check"></i><b>13.8</b> An observational example of sub-sampling</a><ul>
<li class="chapter" data-level="13.8.1" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#plot-the-raw-data"><i class="fa fa-check"></i><b>13.8.1</b> Plot the raw data</a></li>
<li class="chapter" data-level="13.8.2" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#group-to-take-mean-richness-at-each-site-with-same-algal-coverage"><i class="fa fa-check"></i><b>13.8.2</b> Group to take mean richness at each site with same algal coverage</a></li>
<li class="chapter" data-level="13.8.3" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#use-raw-data-with-a-random-effect-for-site"><i class="fa fa-check"></i><b>13.8.3</b> Use raw data with a random effect for site</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#summary-2"><i class="fa fa-check"></i><b>13.9</b> Summary</a></li>
<li class="chapter" data-level="13.10" data-path="design-and-analysis-of-experiments-part-1.html"><a href="design-and-analysis-of-experiments-part-1.html#exercises-4"><i class="fa fa-check"></i><b>13.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="repeat-measures-designs.html"><a href="repeat-measures-designs.html"><i class="fa fa-check"></i><b>14</b> Repeat measures designs</a><ul>
<li class="chapter" data-level="14.1" data-path="repeat-measures-designs.html"><a href="repeat-measures-designs.html#paired-t-test"><i class="fa fa-check"></i><b>14.1</b> Paired t-test</a></li>
<li class="chapter" data-level="14.2" data-path="repeat-measures-designs.html"><a href="repeat-measures-designs.html#mixed-effects-model"><i class="fa fa-check"></i><b>14.2</b> Mixed effects model</a></li>
<li class="chapter" data-level="14.3" data-path="repeat-measures-designs.html"><a href="repeat-measures-designs.html#repeat-measures-with-subsampling"><i class="fa fa-check"></i><b>14.3</b> Repeat measures with subsampling</a><ul>
<li class="chapter" data-level="14.3.1" data-path="repeat-measures-designs.html"><a href="repeat-measures-designs.html#visualising-the-data-1"><i class="fa fa-check"></i><b>14.3.1</b> Visualising the data</a></li>
<li class="chapter" data-level="14.3.2" data-path="repeat-measures-designs.html"><a href="repeat-measures-designs.html#incorrect-model-specification."><i class="fa fa-check"></i><b>14.3.2</b> Incorrect model specification.</a></li>
<li class="chapter" data-level="14.3.3" data-path="repeat-measures-designs.html"><a href="repeat-measures-designs.html#mixed-effect-model"><i class="fa fa-check"></i><b>14.3.3</b> Mixed effect model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="factorial-designs.html"><a href="factorial-designs.html"><i class="fa fa-check"></i><b>15</b> Factorial designs</a><ul>
<li class="chapter" data-level="15.1" data-path="factorial-designs.html"><a href="factorial-designs.html#model-fitting"><i class="fa fa-check"></i><b>15.1</b> Model fitting</a></li>
<li class="chapter" data-level="15.2" data-path="factorial-designs.html"><a href="factorial-designs.html#experiment-with-interactions"><i class="fa fa-check"></i><b>15.2</b> Experiment with interactions</a></li>
<li class="chapter" data-level="15.3" data-path="factorial-designs.html"><a href="factorial-designs.html#full-factorial-with-blocking"><i class="fa fa-check"></i><b>15.3</b> Full factorial with blocking</a><ul>
<li class="chapter" data-level="15.3.1" data-path="factorial-designs.html"><a href="factorial-designs.html#model-not-taking-into-account-blocks"><i class="fa fa-check"></i><b>15.3.1</b> Model not taking into account blocks</a></li>
<li class="chapter" data-level="15.3.2" data-path="factorial-designs.html"><a href="factorial-designs.html#model-with-block-as-a-random-effect."><i class="fa fa-check"></i><b>15.3.2</b> Model with block as a random effect.</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="factorial-designs.html"><a href="factorial-designs.html#split-plot"><i class="fa fa-check"></i><b>15.4</b> Split plot</a><ul>
<li class="chapter" data-level="15.4.1" data-path="factorial-designs.html"><a href="factorial-designs.html#visualising-the-data-2"><i class="fa fa-check"></i><b>15.4.1</b> Visualising the data</a></li>
<li class="chapter" data-level="15.4.2" data-path="factorial-designs.html"><a href="factorial-designs.html#incorrect-model"><i class="fa fa-check"></i><b>15.4.2</b> Incorrect model</a></li>
<li class="chapter" data-level="15.4.3" data-path="factorial-designs.html"><a href="factorial-designs.html#correct-model"><i class="fa fa-check"></i><b>15.4.3</b> Correct model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html"><i class="fa fa-check"></i><b>16</b> Generalised linear models</a><ul>
<li class="chapter" data-level="16.1" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#poisson-regression"><i class="fa fa-check"></i><b>16.1</b> Poisson regression</a></li>
<li class="chapter" data-level="16.2" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#ggplot"><i class="fa fa-check"></i><b>16.2</b> GGplot</a></li>
<li class="chapter" data-level="16.3" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#showing-the-results-with-logged-y"><i class="fa fa-check"></i><b>16.3</b> Showing the results with logged y</a></li>
<li class="chapter" data-level="16.4" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#log-link-function-explained"><i class="fa fa-check"></i><b>16.4</b> Log link function explained</a><ul>
<li class="chapter" data-level="16.4.1" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#likelihood-and-deviance"><i class="fa fa-check"></i><b>16.4.1</b> Likelihood and deviance</a></li>
<li class="chapter" data-level="16.4.2" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#negative-binomial-regression"><i class="fa fa-check"></i><b>16.4.2</b> Negative binomial regression</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#comparing-the-results"><i class="fa fa-check"></i><b>16.5</b> Comparing the results</a></li>
<li class="chapter" data-level="16.6" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#models-with-binomial-errors"><i class="fa fa-check"></i><b>16.6</b> Models with binomial errors</a></li>
<li class="chapter" data-level="16.7" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#the-logit-link-function"><i class="fa fa-check"></i><b>16.7</b> The logit link function</a></li>
<li class="chapter" data-level="16.8" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#exercises-5"><i class="fa fa-check"></i><b>16.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html"><i class="fa fa-check"></i><b>17</b> Modelling with multiple variables</a><ul>
<li class="chapter" data-level="17.1" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#introduction-6"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#example-data"><i class="fa fa-check"></i><b>17.2</b> Example data</a></li>
<li class="chapter" data-level="17.3" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#muliple-regression"><i class="fa fa-check"></i><b>17.3</b> Muliple regression</a><ul>
<li class="chapter" data-level="17.3.1" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#analysis-of-the-distribution-of-variability"><i class="fa fa-check"></i><b>17.3.1</b> Analysis of the distribution of variability</a></li>
<li class="chapter" data-level="17.3.2" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#transformation"><i class="fa fa-check"></i><b>17.3.2</b> Transformation</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#collinearity"><i class="fa fa-check"></i><b>17.4</b> Collinearity</a></li>
<li class="chapter" data-level="17.5" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#model-selection"><i class="fa fa-check"></i><b>17.5</b> Model selection</a><ul>
<li class="chapter" data-level="17.5.1" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#dropping-terms"><i class="fa fa-check"></i><b>17.5.1</b> Dropping terms</a></li>
<li class="chapter" data-level="17.5.2" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#stepwise-model-selection"><i class="fa fa-check"></i><b>17.5.2</b> Stepwise model selection</a></li>
<li class="chapter" data-level="17.5.3" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#the-variance-inflation-factor"><i class="fa fa-check"></i><b>17.5.3</b> The variance inflation factor</a></li>
<li class="chapter" data-level="17.5.4" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#diagnostics-4"><i class="fa fa-check"></i><b>17.5.4</b> Diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#generalised-additive-models"><i class="fa fa-check"></i><b>17.6</b> Generalised Additive Models</a><ul>
<li class="chapter" data-level="17.6.1" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#fitting-a-gam-with-multiple-variables"><i class="fa fa-check"></i><b>17.6.1</b> Fitting a gam with multiple variables</a></li>
<li class="chapter" data-level="17.6.2" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#quick-model-selection-for-gams"><i class="fa fa-check"></i><b>17.6.2</b> Quick model selection for Gams</a></li>
<li class="chapter" data-level="17.6.3" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#akaike-weighting-relative-strength-of-evidence-approach."><i class="fa fa-check"></i><b>17.6.3</b> Akaike weighting, relative strength of evidence approach.</a></li>
<li class="chapter" data-level="17.6.4" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#the-method."><i class="fa fa-check"></i><b>17.6.4</b> The method.</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#tree-models"><i class="fa fa-check"></i><b>17.7</b> Tree models</a><ul>
<li class="chapter" data-level="17.7.1" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#fitting-and-plotting-a-tree-model"><i class="fa fa-check"></i><b>17.7.1</b> Fitting and plotting a tree model</a></li>
<li class="chapter" data-level="17.7.2" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#pruning-the-tree"><i class="fa fa-check"></i><b>17.7.2</b> Pruning the tree</a></li>
</ul></li>
<li class="chapter" data-level="17.8" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#which-technique-to-use"><i class="fa fa-check"></i><b>17.8</b> Which technique to use?</a></li>
<li class="chapter" data-level="17.9" data-path="modelling-with-multiple-variables.html"><a href="modelling-with-multiple-variables.html#references-1"><i class="fa fa-check"></i><b>17.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="analysis-of-multi-species-data.html"><a href="analysis-of-multi-species-data.html"><i class="fa fa-check"></i><b>18</b> Analysis of multi-species data</a><ul>
<li class="chapter" data-level="18.1" data-path="analysis-of-multi-species-data.html"><a href="analysis-of-multi-species-data.html#working-with-the-sites-by-species-matrix"><i class="fa fa-check"></i><b>18.1</b> Working with the sites by species matrix</a><ul>
<li class="chapter" data-level="18.1.1" data-path="analysis-of-multi-species-data.html"><a href="analysis-of-multi-species-data.html#bci-data"><i class="fa fa-check"></i><b>18.1.1</b> BCI data</a></li>
<li class="chapter" data-level="18.1.2" data-path="analysis-of-multi-species-data.html"><a href="analysis-of-multi-species-data.html#reshaping-the-site-by-species-matrix"><i class="fa fa-check"></i><b>18.1.2</b> Reshaping the site by species matrix</a></li>
<li class="chapter" data-level="18.1.3" data-path="analysis-of-multi-species-data.html"><a href="analysis-of-multi-species-data.html#working-with-apply"><i class="fa fa-check"></i><b>18.1.3</b> Working with apply</a></li>
<li class="chapter" data-level="18.1.4" data-path="analysis-of-multi-species-data.html"><a href="analysis-of-multi-species-data.html#working-with-the-long-format-data-frame"><i class="fa fa-check"></i><b>18.1.4</b> Working with the long format data frame</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="analysis-of-multi-species-data.html"><a href="analysis-of-multi-species-data.html#resampling-individuals"><i class="fa fa-check"></i><b>18.2</b> Resampling individuals</a><ul>
<li class="chapter" data-level="18.2.1" data-path="analysis-of-multi-species-data.html"><a href="analysis-of-multi-species-data.html#simpsons-and-shannons-indices"><i class="fa fa-check"></i><b>18.2.1</b> Simpson’s and Shannon’s indices</a></li>
<li class="chapter" data-level="18.2.2" data-path="analysis-of-multi-species-data.html"><a href="analysis-of-multi-species-data.html#exercises-6"><i class="fa fa-check"></i><b>18.2.2</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html"><i class="fa fa-check"></i><b>19</b> Analysing patterns in species composition</a><ul>
<li class="chapter" data-level="19.1" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#differences-between-sites"><i class="fa fa-check"></i><b>19.1</b> Differences between sites</a></li>
<li class="chapter" data-level="19.2" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#mantel-tests"><i class="fa fa-check"></i><b>19.2</b> Mantel tests</a></li>
<li class="chapter" data-level="19.3" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#correlation-with-environmental-variables"><i class="fa fa-check"></i><b>19.3</b> Correlation with environmental variables</a></li>
<li class="chapter" data-level="19.4" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#ordination"><i class="fa fa-check"></i><b>19.4</b> Ordination</a></li>
<li class="chapter" data-level="19.5" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#non-metric-multi-dimensional-scaling-nmds"><i class="fa fa-check"></i><b>19.5</b> Non-metric multi dimensional scaling NMDS</a></li>
<li class="chapter" data-level="19.6" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#single-gradient-nmds"><i class="fa fa-check"></i><b>19.6</b> Single gradient NMDS</a></li>
<li class="chapter" data-level="19.7" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#multiple-axis-nmds"><i class="fa fa-check"></i><b>19.7</b> Multiple axis NMDS</a></li>
<li class="chapter" data-level="19.8" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#clustering"><i class="fa fa-check"></i><b>19.8</b> Clustering</a></li>
<li class="chapter" data-level="19.9" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#clam-test"><i class="fa fa-check"></i><b>19.9</b> Clam test</a></li>
<li class="chapter" data-level="19.10" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#simper"><i class="fa fa-check"></i><b>19.10</b> Simper</a></li>
<li class="chapter" data-level="19.11" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#clustering-by-species"><i class="fa fa-check"></i><b>19.11</b> Clustering by species</a></li>
<li class="chapter" data-level="19.12" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#anosim"><i class="fa fa-check"></i><b>19.12</b> Anosim</a></li>
<li class="chapter" data-level="19.13" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#adonis"><i class="fa fa-check"></i><b>19.13</b> Adonis</a></li>
<li class="chapter" data-level="19.14" data-path="analysing-patterns-in-species-composition.html"><a href="analysing-patterns-in-species-composition.html#canonical-correspondence-analysis"><i class="fa fa-check"></i><b>19.14</b> Canonical Correspondence Analysis</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html"><i class="fa fa-check"></i><b>20</b> Simulating and analysing data from questionnaires</a><ul>
<li class="chapter" data-level="20.1" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#introduction-7"><i class="fa fa-check"></i><b>20.1</b> Introduction</a><ul>
<li class="chapter" data-level="20.1.1" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#packages-used"><i class="fa fa-check"></i><b>20.1.1</b> Packages used</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#simulating-a-single-vector-of-likert-data"><i class="fa fa-check"></i><b>20.2</b> Simulating a single vector of Likert data</a><ul>
<li class="chapter" data-level="20.2.1" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#character-vectors-and-factors"><i class="fa fa-check"></i><b>20.2.1</b> Character vectors and factors</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#numerical-vectors-to-likert-vectors"><i class="fa fa-check"></i><b>20.3</b> Numerical vectors to Likert vectors</a><ul>
<li class="chapter" data-level="20.3.1" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#forming-a-data-frame"><i class="fa fa-check"></i><b>20.3.1</b> Forming a data frame</a></li>
<li class="chapter" data-level="20.3.2" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#adding-question-text"><i class="fa fa-check"></i><b>20.3.2</b> Adding question text</a></li>
<li class="chapter" data-level="20.3.3" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#joining-the-two-tables"><i class="fa fa-check"></i><b>20.3.3</b> Joining the two tables</a></li>
<li class="chapter" data-level="20.3.4" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#plotting-the-results"><i class="fa fa-check"></i><b>20.3.4</b> Plotting the results</a></li>
<li class="chapter" data-level="20.3.5" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#grouping-data"><i class="fa fa-check"></i><b>20.3.5</b> Grouping data</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#simulating-responses-that-differ-between-subject-specific-variables"><i class="fa fa-check"></i><b>20.4</b> Simulating responses that differ between subject specific variables</a><ul>
<li class="chapter" data-level="20.4.1" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#using-the-beta-distribution-to-simulate-likert-data"><i class="fa fa-check"></i><b>20.4.1</b> Using the beta distribution to simulate Likert data</a></li>
<li class="chapter" data-level="20.4.2" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#joining-the-tables"><i class="fa fa-check"></i><b>20.4.2</b> Joining the tables</a></li>
<li class="chapter" data-level="20.4.3" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#section"><i class="fa fa-check"></i><b>20.4.3</b> </a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#statistical-tests"><i class="fa fa-check"></i><b>20.5</b> Statistical tests</a><ul>
<li class="chapter" data-level="20.5.1" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#analysing-as-a-binary-responses"><i class="fa fa-check"></i><b>20.5.1</b> Analysing as a binary responses</a></li>
<li class="chapter" data-level="20.5.2" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#visualising-response-to-a-continuous-variable"><i class="fa fa-check"></i><b>20.5.2</b> Visualising response to a continuous variable</a></li>
<li class="chapter" data-level="20.5.3" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#screening-all-questions"><i class="fa fa-check"></i><b>20.5.3</b> Screening all questions</a></li>
<li class="chapter" data-level="20.5.4" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#latent-factor-analysis"><i class="fa fa-check"></i><b>20.5.4</b> Latent factor analysis</a></li>
<li class="chapter" data-level="20.5.5" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#setting-up-the-data-frame"><i class="fa fa-check"></i><b>20.5.5</b> Setting up the data frame</a></li>
<li class="chapter" data-level="20.5.6" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#data-manipulation"><i class="fa fa-check"></i><b>20.5.6</b> Data manipulation</a></li>
<li class="chapter" data-level="20.5.7" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#correlation-matrix"><i class="fa fa-check"></i><b>20.5.7</b> Correlation matrix</a></li>
<li class="chapter" data-level="20.5.8" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#polychoric-scree-plots"><i class="fa fa-check"></i><b>20.5.8</b> Polychoric scree plots</a></li>
<li class="chapter" data-level="20.5.9" data-path="simulating-and-analysing-data-from-questionnaires.html"><a href="simulating-and-analysing-data-from-questionnaires.html#hierarchical-factors-and-item-response-theory"><i class="fa fa-check"></i><b>20.5.9</b> Hierarchical factors and item response theory</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html"><i class="fa fa-check"></i><b>21</b> Simple text processing with sentiment analysis</a><ul>
<li class="chapter" data-level="21.1" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#introduction-8"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#reading-in-the-data"><i class="fa fa-check"></i><b>21.2</b> Reading in the data</a></li>
<li class="chapter" data-level="21.3" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#making-a-data-frame-consisting-of-just-words"><i class="fa fa-check"></i><b>21.3</b> Making a data frame consisting of just words</a></li>
<li class="chapter" data-level="21.4" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#count-the-frequenciy-of-each-word"><i class="fa fa-check"></i><b>21.4</b> Count the frequenciy of each word</a></li>
<li class="chapter" data-level="21.5" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#word-cloud"><i class="fa fa-check"></i><b>21.5</b> Word cloud</a></li>
<li class="chapter" data-level="21.6" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#find-the-sentiments-associated-with-the-words"><i class="fa fa-check"></i><b>21.6</b> Find the sentiments associated with the words</a></li>
<li class="chapter" data-level="21.7" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#plotting-the-frequencies-of-the-sentiments"><i class="fa fa-check"></i><b>21.7</b> Plotting the frequencies of the sentiments</a></li>
<li class="chapter" data-level="21.8" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#words-associated-with-each-sentiment"><i class="fa fa-check"></i><b>21.8</b> Words associated with each sentiment</a></li>
<li class="chapter" data-level="21.9" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#used-in-a-questionaire-context"><i class="fa fa-check"></i><b>21.9</b> Used in a questionaire context</a></li>
<li class="chapter" data-level="21.10" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#example-one-line-per-tweet"><i class="fa fa-check"></i><b>21.10</b> Example: One line per tweet</a></li>
<li class="chapter" data-level="21.11" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#extracting-the-words"><i class="fa fa-check"></i><b>21.11</b> Extracting the words</a></li>
<li class="chapter" data-level="21.12" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#sentiment-scores"><i class="fa fa-check"></i><b>21.12</b> Sentiment scores</a></li>
<li class="chapter" data-level="21.13" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#is-there-a-relationship-between-the-scores-and-the-number-of-times-the-tweet-is-favourited"><i class="fa fa-check"></i><b>21.13</b> Is there a relationship between the scores and the number of times the tweet is favourited?</a></li>
<li class="chapter" data-level="21.14" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#using-udpipe"><i class="fa fa-check"></i><b>21.14</b> Using Udpipe</a></li>
<li class="chapter" data-level="21.15" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#nouns"><i class="fa fa-check"></i><b>21.15</b> Nouns</a></li>
<li class="chapter" data-level="21.16" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#verbs"><i class="fa fa-check"></i><b>21.16</b> Verbs</a></li>
<li class="chapter" data-level="21.17" data-path="simple-text-processing-with-sentiment-analysis.html"><a href="simple-text-processing-with-sentiment-analysis.html#adjectives"><i class="fa fa-check"></i><b>21.17</b> Adjectives</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-2.html"><a href="references-2.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Quantitative methods</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="generalised-linear-models" class="section level1">
<h1><span class="header-section-number">Chapter 16</span> Generalised linear models</h1>
<p>So far we have assumed throughout that the variability in our models takes an approximately normal form. This is the assumption used in the classical parametric statistical tests and in regression, ANOVA and ANCOVA. Violations of the assumption often lead to the adoption of simple non parametric tests instead of more informative model based procedures due to worries about not meeting the assumptions needed for parametric modelling. However the set of models, known as Generalised Linear Models (GLMs) can use any known distribution for the errors. These are very powerful techniques. They are not much more difficult to apply using R than the methods that you have already seen. However careful thought is required in order to find the correct form for the model.</p>
<div id="poisson-regression" class="section level2">
<h2><span class="header-section-number">16.1</span> Poisson regression</h2>
<p>Let’s look at the marine invertebrates data that we saw earlier.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d&lt;-<span class="kw">read.csv</span>(<span class="st">&quot;https://tinyurl.com/aqm-data/marineinverts.csv&quot;</span>)
<span class="kw">str</span>(d)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    45 obs. of  4 variables:
##  $ richness: int  0 2 8 13 17 10 10 9 19 8 ...
##  $ grain   : num  450 370 192 194 197 ...
##  $ height  : num  2.255 0.865 1.19 -1.336 -1.334 ...
##  $ salinity: num  27.1 27.1 29.6 29.4 29.6 29.4 29.4 29.6 29.6 29.6 ...</code></pre>
<p>Plotting species richness against grain size again.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">attach</span>(d)
<span class="kw">plot</span>(d<span class="op">$</span>richness<span class="op">~</span>d<span class="op">$</span>grain)</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>In the previous analysis we looked at how allowing the model to adopt a curved form led to a better fit. However the issue of the inappropriate use of the normal distribution to represent the error term was ignored.</p>
<p>One way of thinking about the situation is to remember that the description of a regression line includes some statement about the errors.</p>
<p><span class="math inline">\(y=a+bx+\epsilon\)</span> where <span class="math inline">\(\epsilon=N(o,\sigma^{2})\)</span></p>
<p>This equation should be able to describe the process that leads to each data point. The model has a deterministic component (the regression line) and a stochastic component (the error term). However when the points are counts a continuous error term is incorrect. Although the mean value (trend) does not have to be an integer value, the actual data values do. So the errors around the trend should be discrete.</p>
<p>The poisson distribution can represent this. For any value of lambda (which is continuous) the probability distribution of values is discrete. The poisson distribution automatically builds in heterogeniety of variance as the variance of a poisson distribution is in fact equal to lambda.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfcol=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">barplot</span>(<span class="kw">dpois</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>,<span class="dt">lambda=</span><span class="fl">0.1</span>),<span class="dt">names=</span><span class="dv">0</span><span class="op">:</span><span class="dv">5</span>,<span class="dt">main=</span><span class="st">&quot;Lambda=0.1&quot;</span>)
<span class="kw">barplot</span>(<span class="kw">dpois</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>,<span class="dt">lambda=</span><span class="fl">0.5</span>),<span class="dt">names=</span><span class="dv">0</span><span class="op">:</span><span class="dv">5</span>,<span class="dt">main=</span><span class="st">&quot;Lambda=0.5&quot;</span>)
<span class="kw">barplot</span>(<span class="kw">dpois</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>,<span class="dt">lambda=</span><span class="dv">1</span>),<span class="dt">names=</span><span class="dv">0</span><span class="op">:</span><span class="dv">5</span>,<span class="dt">main=</span><span class="st">&quot;Lambda=1&quot;</span>)
<span class="kw">barplot</span>(<span class="kw">dpois</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>,<span class="dt">lambda=</span><span class="dv">2</span>),<span class="dt">names=</span><span class="dv">0</span><span class="op">:</span><span class="dv">5</span>,<span class="dt">main=</span><span class="st">&quot;Lambda=2&quot;</span>)</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Let’s think of a regression line with poisson errors with a=0, and b=1.</p>
<p><span class="math inline">\(y=a+bx+\epsilon\)</span> where <span class="math inline">\(\epsilon=poisson(lambda=y)\)</span></p>
<p>Something interesting happens in this case. Lambda is a measure of the central tendency, but for most of the regression line no observations can actually take the value of lambda. A point can only fall on the line when lambda happens to be an integer.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lambda&lt;-<span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dt">length=</span><span class="dv">200</span>)
<span class="kw">plot</span>(lambda,<span class="kw">rpois</span>(<span class="dv">200</span>,lambda),<span class="dt">pch=</span><span class="dv">21</span>,<span class="dt">bg=</span><span class="dv">2</span>)
<span class="kw">lines</span>(lambda,lambda,<span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">0</span><span class="op">:</span><span class="dv">10</span>,<span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>This is the motive for fitting using maximum likelihood. A point that falls a long way away from the deterministic component of a model contributes more to the model’s deviance than one that is close. A model with a low total deviance has a higher likelihood than one with a high deviance. The probabilities (that contribute to the deviance) are determined from assumptions regarding the form of the stochastic component of the model. The normal distribution is only one form of determining these probabilities. There are many other possible distributions for the error term.</p>
<p>So let’s fit the model again, this time using poisson regression. By default this uses a log link function. This is usually appropriate for count data that cannot fall below zero. In this case the logarithmic link function also deals nicely with the problem of curvilinearity of the response.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod1&lt;-<span class="kw">glm</span>(<span class="dt">data=</span>d,richness <span class="op">~</span><span class="st"> </span>grain,<span class="dt">family=</span>poisson)
<span class="kw">summary</span>(mod1)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = richness ~ grain, family = poisson, data = d)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.4828  -1.3897  -0.0732   0.8644   2.5838  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  4.238393   0.299033  14.174  &lt; 2e-16 ***
## grain       -0.009496   0.001179  -8.052 8.16e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 179.75  on 44  degrees of freedom
## Residual deviance: 105.35  on 43  degrees of freedom
## AIC: 251.35
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(mod1)</code></pre></div>
<pre><code>## Waiting for profiling to be done...</code></pre>
<pre><code>##                   2.5 %       97.5 %
## (Intercept)  3.65451714  4.827458978
## grain       -0.01185141 -0.007224939</code></pre>
<p>Plotting the model shows it’s form. Note that with when fitting a GLM in R we can ask for the standard errors and produce approximate confidence intervals using them.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(d<span class="op">$</span>richness <span class="op">~</span><span class="st"> </span>d<span class="op">$</span>grain)
x&lt;-<span class="kw">seq</span>(<span class="kw">min</span>(d<span class="op">$</span>grain),<span class="kw">max</span>(d<span class="op">$</span>grain),<span class="dt">length=</span><span class="dv">100</span>)
a&lt;-<span class="kw">predict</span>(mod1,<span class="dt">newdata=</span><span class="kw">list</span>(<span class="dt">grain=</span>x),<span class="dt">type=</span><span class="st">&quot;response&quot;</span>,<span class="dt">se=</span>T) 
<span class="kw">lines</span>(x,a<span class="op">$</span>fit<span class="op">-</span><span class="dv">2</span><span class="op">*</span>a<span class="op">$</span>se.fit,<span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">lines</span>(x,a<span class="op">$</span>fit<span class="op">+</span><span class="dv">2</span><span class="op">*</span>a<span class="op">$</span>se.fit,<span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">lines</span>(x,a<span class="op">$</span>fit)</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="ggplot" class="section level2">
<h2><span class="header-section-number">16.2</span> GGplot</h2>
<p>Its easy to add a glm to a ggplot scatterplot. However be careful to add in the methods.args.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
g0&lt;-<span class="kw">ggplot</span>(d,<span class="kw">aes</span>(<span class="dt">x=</span>grain,<span class="dt">y=</span>richness))
glm1&lt;-g0<span class="op">+</span><span class="kw">geom_point</span>()<span class="op">+</span><span class="kw">stat_smooth</span>(<span class="dt">method=</span><span class="st">&quot;glm&quot;</span>,<span class="dt">method.args=</span><span class="kw">list</span>( <span class="dt">family=</span><span class="st">&quot;poisson&quot;</span>), <span class="dt">se=</span><span class="ot">TRUE</span>) <span class="op">+</span><span class="kw">ggtitle</span>(<span class="st">&quot;Poisson regression with log link function&quot;</span>)
glm1</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="showing-the-results-with-logged-y" class="section level2">
<h2><span class="header-section-number">16.3</span> Showing the results with logged y</h2>
<p>This is <strong>not</strong> a good approach, as the zeros are lost, but it demonstrates the idea.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(d<span class="op">$</span>richness <span class="op">~</span>d<span class="op">$</span>grain, <span class="dt">log=</span><span class="st">&quot;y&quot;</span>)</code></pre></div>
<pre><code>## Warning in xy.coords(x, y, xlabel, ylabel, log): 3 y values &lt;= 0 omitted
## from logarithmic plot</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x&lt;-<span class="kw">seq</span>(<span class="kw">min</span>(grain),<span class="kw">max</span>(grain),<span class="dt">length=</span><span class="dv">100</span>)
a&lt;-<span class="kw">predict</span>(mod1,<span class="dt">newdata=</span><span class="kw">list</span>(<span class="dt">grain=</span>x),<span class="dt">type=</span><span class="st">&quot;response&quot;</span>,<span class="dt">se=</span>T) 
<span class="kw">lines</span>(x,a<span class="op">$</span>fit<span class="op">-</span><span class="dv">2</span><span class="op">*</span>a<span class="op">$</span>se.fit,<span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">lines</span>(x,a<span class="op">$</span>fit<span class="op">+</span><span class="dv">2</span><span class="op">*</span>a<span class="op">$</span>se.fit,<span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">lines</span>(x,a<span class="op">$</span>fit)</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="log-link-function-explained" class="section level2">
<h2><span class="header-section-number">16.4</span> Log link function explained</h2>
<p>The coefficients of the model when we ask for a summary are rather hard to undertand.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(mod1)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = richness ~ grain, family = poisson, data = d)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.4828  -1.3897  -0.0732   0.8644   2.5838  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  4.238393   0.299033  14.174  &lt; 2e-16 ***
## grain       -0.009496   0.001179  -8.052 8.16e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 179.75  on 44  degrees of freedom
## Residual deviance: 105.35  on 43  degrees of freedom
## AIC: 251.35
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>The slope is given as -0.009. What does this mean? Unlike a regeression slope it is <strong>NOT</strong> the change in y for a unit change in x, as we are using a logarithmic link function.</p>
<p>In generalized linear models, there is always some sort of link function, which is the link between the mean of Y on the left and the predictor variable on the right. It is possible to use the identity link, which leaves the result the same, but typically some other link function is used. The identity link is not a good choice for data with many zeros.</p>
<p>Formally the link function is ..</p>
<p><span class="math inline">\(f(y|x ) = a + bx\)</span></p>
<p>I.e. Some function of the conditional value of y on x, ignoring the residual error, is predicted by a regression equation rather than simply y.</p>
<p>The log link function exponentiates the linear predictors. It <strong>does not</strong> actually involve a log transform of the outcome variable.</p>
<p><span class="math inline">\(y = exp(a + bx)\)</span></p>
<p>Which could be also written as ..</p>
<p><span class="math inline">\(y = e^{a +bx}\)</span></p>
<p>As the logarithm used is the natural logarithm this implies that expected value of y is <strong>multiplied</strong> by <span class="math inline">\(exp(b)\)</span> as we increase the value of x by 1 unit.</p>
<p>This is not intuitive.</p>
<p>Exponentiating the coefficients in R for the model above produces this result..</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(mod1))</code></pre></div>
<pre><code>## (Intercept)       grain 
##  69.2963902   0.9905485</code></pre>
<p>So, the intercept,for a grain size of zero is 69.3 and for each unit increase in grain size the diversity is changed by 99.055 % of the previous value. This is a process of exponential decay, as the richness is falling away steadily with each unti increase in grain size, but the model never leads to a predicted species richness below zero.</p>
<p>One way to make all this a little more understandable is to divide the natural logarithm of 2 (0.69) by the raw slope coefficient, which was found to be -0.009.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">log</span>(<span class="dv">2</span>)<span class="op">/</span>(<span class="kw">coef</span>(mod1)[<span class="dv">2</span>])</code></pre></div>
<pre><code>##     grain 
## -72.99001</code></pre>
<p>This is using the formula for the half life, or doubling time, in an expenential decay or growth model.</p>
<p>So, in order to double the expected species richness we therefore would have to change the grain size by -72.99 units.</p>
<p>When presenting the results to a mathematically sophisticated audience you can safely place the coefficients within the equation and expect the audience to make sense of it.</p>
<p><span class="math inline">\(y = e^{a +bx}\)</span></p>
<p>When explaining the result in words you can say that a change in grain size of -72.99 leads to doubling of expected species richness.</p>
<p>Showing a scatterplot with the fitted line is usually the easiest way to visualise the model and to make sense of it intuitively.</p>
<div id="likelihood-and-deviance" class="section level3">
<h3><span class="header-section-number">16.4.1</span> Likelihood and deviance</h3>
<p>In order to fully understand all the elements used when analysing a GLM we also need at least an intuitive understanding of the concepts of likelihood and deviance.</p>
<p>Models are fit by maximising the likelihood. But, what is the likelihood?</p>
<p>To try to inderstand this, let’s first obtain some simple count data. We can simulate the counts from a poisson distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)
x&lt;-<span class="kw">rpois</span>(<span class="dv">10</span>,<span class="dt">lambda=</span><span class="dv">2</span>)
x</code></pre></div>
<pre><code>##  [1] 1 1 2 4 1 4 4 2 2 0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">barplot</span>(<span class="kw">table</span>(x))</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>We can fit a simple model that just involves the intercept (mean) using R. This is.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod&lt;-<span class="kw">glm</span>(x<span class="op">~</span><span class="dv">1</span>,<span class="kw">poisson</span>(<span class="dt">link=</span><span class="st">&quot;identity&quot;</span>))
<span class="kw">summary</span>(mod)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = x ~ 1, family = poisson(link = &quot;identity&quot;))
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.04939  -0.84624  -0.06957   0.85560   1.16398  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   2.1000     0.4583   4.583 4.59e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 10.427  on 9  degrees of freedom
## Residual deviance: 10.427  on 9  degrees of freedom
## AIC: 36.066
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(mod)</code></pre></div>
<pre><code>## (Intercept) 
##         2.1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(mod)</code></pre></div>
<pre><code>## Waiting for profiling to be done...</code></pre>
<pre><code>##    2.5 %   97.5 % 
## 1.325155 3.130620</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lam&lt;-<span class="kw">coef</span>(mod)</code></pre></div>
<p>Now, under the poisson model we can calculate a probability of getting any integer from a poisson distribution with a mean of lambda using a standard formula that is built into R. So the probability of getting a zero is dpois(0,lambda=2.1)</p>
<p>dpois(0,lambda=2.1)=0.122</p>
<p>dpois(1,lambda=2.1)=0.257</p>
<p>dpois(2,lambda=2.1)= 0.27</p>
<p>dpois(3,lambda=2.1)=0.189</p>
<p>dpois(4,lambda=2.1)=0.099</p>
<p>What this means is that we have a probability (likelihood) for each of the data points given the model parameter (lambda). We can look at this as a barplot of counts of each probability value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dx&lt;-<span class="kw">dpois</span>(x,<span class="dt">lambda=</span>lam)
dx</code></pre></div>
<pre><code>##  [1] 0.25715850 0.25715850 0.27001642 0.09923104 0.25715850 0.09923104
##  [7] 0.09923104 0.27001642 0.27001642 0.12245643</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">barplot</span>(<span class="kw">table</span>(<span class="kw">round</span>(dx,<span class="dv">3</span>)))</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>The probability of getting <strong>EXACTLY</strong> the data that we have is the product of all these probabilities, as we find the combined probability of independent events by multiplying them together. Because this is going to result in very small numbers it is usually easier to work with logarithmns and add them together. Hence the term log likelihood that you will see used in all treatments of GLMs.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loglik&lt;-<span class="kw">sum</span>(<span class="kw">log</span>(dx))
loglik</code></pre></div>
<pre><code>## [1] -17.03292</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">logLik</span>(mod)</code></pre></div>
<pre><code>## &#39;log Lik.&#39; -17.03292 (df=1)</code></pre>
<p>OK, so that was not too difficult. Notice as well that this calculation gave us the maximum likelihood. If we had used any other value as an estimate for lambda we would have got a lower value expressed as a negative value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">dpois</span>(x,<span class="dt">lambda=</span><span class="dv">1</span>)))</code></pre></div>
<pre><code>## [1] -21.6136</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">dpois</span>(x,<span class="dt">lambda=</span>lam)))</code></pre></div>
<pre><code>## [1] -17.03292</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">dpois</span>(x,<span class="dt">lambda=</span><span class="dv">3</span>)))</code></pre></div>
<pre><code>## [1] -18.54274</code></pre>
<p>In order to simplify matters further we remove the sign and work with -2 log likelihood.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="op">-</span><span class="dv">2</span><span class="op">*</span><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">dpois</span>(x,<span class="dt">lambda=</span>lam)))</code></pre></div>
<pre><code>## [1] 34.06584</code></pre>
<p>The AIC which we will look at later in the course as a way of comparing two models combines the -2 log likelihood with the number of parameters (k). In this case we have just one parameter so AIC adds 2 to the number we previously calculated.</p>
<p>AIC=2k-2ln(L)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(mod)</code></pre></div>
<pre><code>## [1] 36.06584</code></pre>
<p>Now finally, what does the deviance refer to?</p>
<p>Well, even a model which has a separate parameter for each data point will still have a likelihood below one. The deviance refers to the difference in -2 log likelihood between the fully saturated model and the actual model. We can get the -2 log likelihood for this model as well.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dpois</span>(x,<span class="dt">lambda=</span>x)</code></pre></div>
<pre><code>##  [1] 0.3678794 0.3678794 0.2706706 0.1953668 0.3678794 0.1953668 0.1953668
##  [8] 0.2706706 0.2706706 1.0000000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">satmod&lt;-<span class="op">-</span><span class="dv">2</span><span class="op">*</span><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">dpois</span>(x,<span class="dt">lambda=</span>x)))
satmod</code></pre></div>
<pre><code>## [1] 23.63838</code></pre>
<p>Just to confirm, this should give us the deviance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="op">-</span><span class="dv">2</span><span class="op">*</span>loglik<span class="op">-</span>satmod</code></pre></div>
<pre><code>## [1] 10.42746</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">deviance</span>(mod)</code></pre></div>
<pre><code>## [1] 10.42746</code></pre>
<p>Notice that we had ten data points (residual degrees of freedom = n-1 = 9) and a residual deviance that is around 10. This is an indication that the assumption of Poisson distributed residuals is a reasonable one as for mathematical reasons that we need not go into we would expect an addition of just under 1 to the deviance for each additional data point.</p>
<p>Going back to the summary of the model</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(mod)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = x ~ 1, family = poisson(link = &quot;identity&quot;))
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.04939  -0.84624  -0.06957   0.85560   1.16398  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   2.1000     0.4583   4.583 4.59e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 10.427  on 9  degrees of freedom
## Residual deviance: 10.427  on 9  degrees of freedom
## AIC: 36.066
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<p>We can see that in this artificial case the null deviance and the residual deviance are identical. This is because the null is “true”. There is nothing to report in the model apart from the intercept, i.e. a single value for lambda. If we use this concept in a model with a predictor variable we should see a difference between these two numbers. The larger the diffence, the more of the deviance is “explained” by our predictor. We want to reduce the deviance bt fitting a model, so if there is a relationship the residual deviance should always be lower than the null deviance.</p>
<div id="overdispersion" class="section level4">
<h4><span class="header-section-number">16.4.1.1</span> Overdispersion</h4>
<p>If the residual deviance is larger than residual degrees of freedom we have overdispersion (extra, unexplained variation in the response).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(mod1)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = richness ~ grain, family = poisson, data = d)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.4828  -1.3897  -0.0732   0.8644   2.5838  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  4.238393   0.299033  14.174  &lt; 2e-16 ***
## grain       -0.009496   0.001179  -8.052 8.16e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 179.75  on 44  degrees of freedom
## Residual deviance: 105.35  on 43  degrees of freedom
## AIC: 251.35
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>This means that in fact the measured variance in the data, after taking into account the regression line, is still larger than the lambda values over the range of the regression. This is extra variability that goes beyond that expected under the assumption that the residuals are poisson distributed.</p>
<p>This is the diagnostic tool which is used in Poisson regression. The point is that under a poisson distribution the variance is fixed. It is always identical to the mean (lamda). This may not be a reasonable assumption, but it is the assumption being made. If it is not met we will need to make some compensation for this in order to produce a more justifiable model.</p>
</div>
<div id="quasi-poisson-regression" class="section level4">
<h4><span class="header-section-number">16.4.1.2</span> Quasi-poisson regression</h4>
<p>A simple way of dealing with over dispersion is to use so called quasi-poisson regression. This finds a weight so that instead of assuming that the variance is equal to lambda the assumption is made that it is equal to some multiple of lambda. The multiple is estimated from the data. The effect is to reduce the significance of the regression term and widen the confidence intervals. It is a rather outdated technique that has some problems, but we’ll try it anyway.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod2&lt;-<span class="kw">glm</span>(<span class="dt">data=</span>d,richness <span class="op">~</span><span class="st"> </span>grain,<span class="dt">family=</span>quasipoisson)
<span class="kw">summary</span>(mod2)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = richness ~ grain, family = quasipoisson, data = d)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.4828  -1.3897  -0.0732   0.8644   2.5838  
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.238393   0.441806   9.593 3.00e-12 ***
## grain       -0.009496   0.001743  -5.450 2.29e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 2.182862)
## 
##     Null deviance: 179.75  on 44  degrees of freedom
## Residual deviance: 105.35  on 43  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(mod2)</code></pre></div>
<pre><code>## [1] NA</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(mod2)</code></pre></div>
<pre><code>## Waiting for profiling to be done...</code></pre>
<pre><code>##                 2.5 %      97.5 %
## (Intercept)  3.376924  5.11119746
## grain       -0.013008 -0.00616704</code></pre>
<p>Notice that the confidence intervals are wider. However we cannot obtain a value for AIC from a quasi model as the likelihood function is not fully defined. This limits the application of quasi poisson models, so we’ll pass on quickly to a rather more useful approach..</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm2&lt;-g0<span class="op">+</span><span class="kw">geom_point</span>()<span class="op">+</span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;glm&quot;</span>, <span class="dt">method.args=</span><span class="kw">list</span>(<span class="dt">family=</span><span class="st">&quot;quasipoisson&quot;</span>), <span class="dt">se=</span><span class="ot">TRUE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Quasipoisson regression&quot;</span>)
glm2</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
</div>
</div>
<div id="negative-binomial-regression" class="section level3">
<h3><span class="header-section-number">16.4.2</span> Negative binomial regression</h3>
<p>As we have seen, there is a problem with quasi poisson regression.There is no defined form for the likelihood. Therefore it is impossible to calculate AIC. This makes it difficult to run model comparisons using quasi poisson models. An alternative is to fit the model assuming a negative binomial distribution for the error terms. This is a well defined model for over dispersed count data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
mod3&lt;-<span class="kw">glm.nb</span>(<span class="dt">data=</span>d,richness <span class="op">~</span><span class="st"> </span>grain)
<span class="kw">summary</span>(mod3)</code></pre></div>
<pre><code>## 
## Call:
## glm.nb(formula = richness ~ grain, data = d, init.theta = 4.008462461, 
##     link = log)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.7113  -1.0326  -0.1109   0.5508   1.5622  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.886804   0.467175   8.320  &lt; 2e-16 ***
## grain       -0.008155   0.001713  -4.762 1.92e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Negative Binomial(4.0085) family taken to be 1)
## 
##     Null deviance: 79.302  on 44  degrees of freedom
## Residual deviance: 51.719  on 43  degrees of freedom
## AIC: 235.37
## 
## Number of Fisher Scoring iterations: 1
## 
## 
##               Theta:  4.01 
##           Std. Err.:  1.66 
## 
##  2 x log-likelihood:  -229.37</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(mod3)</code></pre></div>
<pre><code>## Waiting for profiling to be done...</code></pre>
<pre><code>##                   2.5 %       97.5 %
## (Intercept)  3.04704214  4.753670460
## grain       -0.01133949 -0.005064891</code></pre>
<p>Notice that the AIC for the negative binomial model is much lower than that for the (incorrect) poisson model. The residual deviance is now not much larger than the residual degrees of freedom. It is very important to include the overdispersion rather than use the assumption that the variance is equal to lambda that is built into poisson regression.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(mod1)</code></pre></div>
<pre><code>## [1] 251.3523</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(mod3)</code></pre></div>
<pre><code>## [1] 235.3695</code></pre>
<p>The variance of the negative binomial is</p>
<p><span class="math inline">\(var=\mu+\frac{\mu^{2}}{\theta}\)</span></p>
<p>So theta controls the excess variability compared to Poisson. The smaller the value of theta the more skewed the distribution becomes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfcol=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">hist</span>(<span class="kw">rnegbin</span>(<span class="dt">n=</span><span class="dv">10000</span>,<span class="dt">mu=</span><span class="dv">10</span>,<span class="dt">theta=</span><span class="dv">100</span>),<span class="dt">main=</span><span class="st">&quot;Theta=100&quot;</span>,<span class="dt">col=</span><span class="st">&quot;grey&quot;</span>)
<span class="kw">hist</span>(<span class="kw">rnegbin</span>(<span class="dt">n=</span><span class="dv">10000</span>,<span class="dt">mu=</span><span class="dv">10</span>,<span class="dt">theta=</span><span class="dv">10</span>),<span class="dt">main=</span><span class="st">&quot;Theta=10&quot;</span>,<span class="dt">col=</span><span class="st">&quot;grey&quot;</span>)
<span class="kw">hist</span>(<span class="kw">rnegbin</span>(<span class="dt">n=</span><span class="dv">10000</span>,<span class="dt">mu=</span><span class="dv">10</span>,<span class="dt">theta=</span><span class="dv">1</span>),<span class="dt">main=</span><span class="st">&quot;Theta=1&quot;</span>,<span class="dt">col=</span><span class="st">&quot;grey&quot;</span>)
<span class="kw">hist</span>(<span class="kw">rnegbin</span>(<span class="dt">n=</span><span class="dv">10000</span>,<span class="dt">mu=</span><span class="dv">10</span>,<span class="dt">theta=</span><span class="fl">0.1</span>),<span class="dt">main=</span><span class="st">&quot;Theta=0.1&quot;</span>,<span class="dt">col=</span><span class="st">&quot;grey&quot;</span>)</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>Plotting the model produces a very similar result to that shown by the quasipoisson model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm3&lt;-g0<span class="op">+</span><span class="kw">geom_point</span>()<span class="op">+</span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;glm.nb&quot;</span>, <span class="dt">se=</span><span class="ot">TRUE</span>) <span class="op">+</span><span class="kw">ggtitle</span>(<span class="st">&quot;Negative binomial regression&quot;</span>)
glm3</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
</div>
</div>
<div id="comparing-the-results" class="section level2">
<h2><span class="header-section-number">16.5</span> Comparing the results</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
g0&lt;-<span class="kw">ggplot</span>(d,<span class="kw">aes</span>(<span class="dt">x=</span>grain,<span class="dt">y=</span>richness))
glm1&lt;-g0<span class="op">+</span><span class="kw">geom_point</span>()<span class="op">+</span><span class="kw">stat_smooth</span>(<span class="dt">method=</span><span class="st">&quot;glm&quot;</span>,<span class="dt">method.args=</span><span class="kw">list</span>( <span class="dt">family=</span><span class="st">&quot;poisson&quot;</span>), <span class="dt">se=</span><span class="ot">TRUE</span>) 
glm3&lt;-glm1<span class="op">+</span><span class="kw">geom_point</span>()<span class="op">+</span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;glm.nb&quot;</span>, <span class="dt">se=</span><span class="ot">TRUE</span>,<span class="dt">color=</span><span class="st">&quot;red&quot;</span>) 
glm3</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pscl)</code></pre></div>
<pre><code>## Classes and Methods for R developed in the
## Political Science Computational Laboratory
## Department of Political Science
## Stanford University
## Simon Jackman
## hurdle and zeroinfl functions by Achim Zeileis</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modh&lt;-<span class="kw">hurdle</span>(d<span class="op">$</span>richness<span class="op">~</span>grain,<span class="dt">dist=</span><span class="st">&quot;negbin&quot;</span>)
<span class="kw">summary</span>(modh)</code></pre></div>
<pre><code>## 
## Call:
## hurdle(formula = d$richness ~ grain, dist = &quot;negbin&quot;)
## 
## Pearson residuals:
##     Min      1Q  Median      3Q     Max 
## -1.5804 -0.8495 -0.1085  0.6236  2.0657 
## 
## Count model coefficients (truncated negbin with log link):
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.915924   0.458802   8.535  &lt; 2e-16 ***
## grain       -0.008220   0.001724  -4.767 1.87e-06 ***
## Log(theta)   1.510256   0.510987   2.956  0.00312 ** 
## Zero hurdle model coefficients (binomial with logit link):
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  7.34139    3.39460   2.163   0.0306 *
## grain       -0.01531    0.01005  -1.524   0.1275  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 
## 
## Theta: count = 4.5279
## Number of iterations in BFGS optimization: 13 
## Log-likelihood: -114.5 on 5 Df</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(modh)</code></pre></div>
<pre><code>## [1] 238.9305</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(mod3)</code></pre></div>
<pre><code>## [1] 235.3695</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(modh)</code></pre></div>
<pre><code>##                         2.5 %       97.5 %
## count_(Intercept)  3.01668827  4.815159689
## count_grain       -0.01159973 -0.004840422
## zero_(Intercept)   0.68811013 13.994679574
## zero_grain        -0.03500187  0.004381010</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modzi &lt;-<span class="st"> </span><span class="kw">zeroinfl</span>(<span class="dt">data=</span>d,richness<span class="op">~</span>grain,<span class="dt">dist=</span><span class="st">&quot;negbin&quot;</span>)
<span class="kw">summary</span>(modzi)</code></pre></div>
<pre><code>## 
## Call:
## zeroinfl(formula = richness ~ grain, data = d, dist = &quot;negbin&quot;)
## 
## Pearson residuals:
##     Min      1Q  Median      3Q     Max 
## -1.5740 -0.8408 -0.1085  0.6161  2.0427 
## 
## Count model coefficients (negbin with log link):
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.896314   0.446411   8.728  &lt; 2e-16 ***
## grain       -0.008132   0.001659  -4.902 9.49e-07 ***
## Log(theta)   1.514259   0.514694   2.942  0.00326 ** 
## 
## Zero-inflation model coefficients (binomial with logit link):
##             Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -5.37854   11.19100  -0.481    0.631
## grain        0.00447    0.03878   0.115    0.908
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 
## 
## Theta = 4.5461 
## Number of iterations in BFGS optimization: 35 
## Log-likelihood: -114.6 on 5 Df</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(modh)</code></pre></div>
<pre><code>## [1] 238.9305</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(modzi)</code></pre></div>
<pre><code>## [1] 239.1852</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(mod3)</code></pre></div>
<pre><code>## [1] 235.3695</code></pre>
</div>
<div id="models-with-binomial-errors" class="section level2">
<h2><span class="header-section-number">16.6</span> Models with binomial errors</h2>
<p>The most commonly used GL is probably logistic regression. In this particular model the response can only take values of zero or one. Thus it is clear from the outset that errors cannot be normal. Let’s set up a simple simulated data set to show how this works. Imagine we are interested in mortality of pine trees following a ground fire. We might assume that the population of tree diameters are log normally distributed with a mean of twenty.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)
diam&lt;-<span class="kw">sort</span>(<span class="kw">rlnorm</span>(<span class="dv">500</span>,<span class="dt">mean=</span><span class="kw">log</span>(<span class="dv">20</span>),<span class="dt">sd=</span><span class="fl">0.5</span>))
<span class="kw">summary</span>(diam)</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   4.445  14.660  19.636  23.018  28.079 134.407</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(diam,<span class="dt">col=</span><span class="st">&quot;grey&quot;</span>,<span class="dt">breaks=</span><span class="dv">10</span>)</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>Let’s simulate some response data based on an extremely simple underlying pattern for tree mortality. We might assume that trees with diameters of over 40 cm have bark that has reached a thickness that prevents the tree being killed by the fire. We might also assume a simple linear relationship between diameter and mortality up to this threshold and build a simple rule based vector of the probability that a tree survives the fire as a function of its diameter.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p&lt;-diam<span class="op">/</span><span class="dv">50</span> 
p[p<span class="op">&gt;</span><span class="dv">1</span>]&lt;-<span class="dv">1</span> 
<span class="kw">plot</span>(diam,p,<span class="dt">ylab=</span><span class="st">&quot;Survival probability&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;Diameter&quot;</span>,<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">lwd=</span><span class="dv">3</span>)</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p>Although we have a very simple underlying deterministic model, we will not see this directly when we collect data. Any individual tree will be either alive or dead. Thus our response will be zeros and ones. This is the problem that logistic regression deals with very neatly without the need to calculate proportions explicitly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f&lt;-<span class="cf">function</span>(x)<span class="kw">rbinom</span>(<span class="dv">1</span>,<span class="dv">1</span>,x)
response&lt;-<span class="kw">as.vector</span>(<span class="kw">sapply</span>(p,f))
<span class="kw">head</span>(response)</code></pre></div>
<pre><code>## [1] 0 0 0 1 0 0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d&lt;-<span class="kw">data.frame</span>(diam,response)
<span class="kw">plot</span>(diam,response)
<span class="kw">lines</span>(diam,p,<span class="dt">lwd=</span><span class="dv">3</span>)</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<p>The task for the statistical model is to take this input and turn it back into a response model. Generalised linear models do this using a link function. In R it is very easy to specify the model. We simply write a model using the same syntax as for a linear model (one with gaussian errors) but we state the family of models we wish to use as binomial.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod1&lt;-<span class="kw">glm</span>(response<span class="op">~</span>diam,<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
<span class="kw">summary</span>(mod1)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = response ~ diam, family = &quot;binomial&quot;)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.8202  -0.8891  -0.6053   1.0175   2.0428  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -2.60771    0.28033  -9.302   &lt;2e-16 ***
## diam         0.10869    0.01217   8.929   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 688.91  on 499  degrees of freedom
## Residual deviance: 565.51  on 498  degrees of freedom
## AIC: 569.51
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>We can see that R does find a model that matches the underlying pattern very well by using the model for prediction. Again we visualise the model in order to understand it. This is always preferable to trying to understand a model from a table of numbers. Visualisation is particularly important for models with parameters expressed on a logit scale as this is not intuitive.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">g0 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(d,<span class="kw">aes</span>(<span class="dt">x=</span>diam,<span class="dt">y=</span>response))
g1&lt;-g0<span class="op">+</span><span class="kw">geom_point</span>()<span class="op">+</span><span class="kw">stat_smooth</span>(<span class="dt">method=</span><span class="st">&quot;glm&quot;</span>,<span class="dt">method.args=</span><span class="kw">list</span>(<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)) 
g1</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>If we wanted to check whether there was a response shape that differed from that assumed by the general linear model we could try a general additive model with a smoother.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mgcv)</code></pre></div>
<pre><code>## Loading required package: nlme</code></pre>
<pre><code>## This is mgcv 1.8-24. For overview type &#39;help(&quot;mgcv-package&quot;)&#39;.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">g1&lt;-g0<span class="op">+</span><span class="kw">geom_point</span>()<span class="op">+</span><span class="kw">stat_smooth</span>(<span class="dt">method=</span><span class="st">&quot;gam&quot;</span>,<span class="dt">method.args=</span><span class="kw">list</span>(<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>),<span class="dt">formula=</span>y<span class="op">~</span><span class="kw">s</span>(x)) 
g1</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>The curve is very similar. Note that as the smoother uses a form of “local” regression the confidence intervals expand in areas where there is little data.</p>
<p>In some cases the response would take a different form. This could happen if there were some optimum point at which some response occurred, for example the occurence of a species along an altitudinal gradient or shoreline. In this case the gam model would fit the data better than the linear model. We will look at how this can be tested formally later. A quick test is to calculate the AIC. If this is much lower for the gam it indicates that the gam may be a better fit.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm_mod&lt;-<span class="kw">glm</span>(<span class="dt">data=</span>d, response<span class="op">~</span>diam, <span class="dt">family=</span>binomial)
gam_mod&lt;-<span class="kw">gam</span>(<span class="dt">data=</span>d, response<span class="op">~</span><span class="kw">s</span>(diam), <span class="dt">family=</span>binomial)

<span class="kw">AIC</span>(glm_mod)</code></pre></div>
<pre><code>## [1] 569.5078</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(gam_mod)</code></pre></div>
<pre><code>## [1] 566.4594</code></pre>
<p>In this case it is very slightly lower, but not enough to suggest the use of a gam.</p>
</div>
<div id="the-logit-link-function" class="section level2">
<h2><span class="header-section-number">16.7</span> The logit link function</h2>
<p>The logit link function used in binomial glms makes the slope of the line quite difficult to understand. In most cases this doesn’t matter much, as you can concentrate on the sign and signficance of the parameter and show the line as a figure. However when analysing differences in response as a function of levels of a factor you do need to understand the logit link.</p>
<p>To illustrate let’s take a very simple example. Ten leaves are classified as being taken from shade or sun and classified for presence of rust.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(purrr)
<span class="kw">set.seed</span>(<span class="dv">1</span>)
light&lt;-<span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;shade&quot;</span>,<span class="st">&quot;sun&quot;</span>),<span class="dt">each=</span><span class="dv">10</span>)
presence&lt;-<span class="dv">1</span><span class="op">*</span><span class="kw">c</span>(<span class="kw">rbernoulli</span>(<span class="dv">10</span>,<span class="dt">p=</span><span class="fl">0.5</span>),<span class="kw">rbernoulli</span>(<span class="dv">10</span>,<span class="dt">p=</span><span class="fl">0.1</span>))
d&lt;-<span class="kw">data.frame</span>(light,presence)</code></pre></div>
<p>We can get a table of the results easily.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(d)</code></pre></div>
<pre><code>##        presence
## light   0 1
##   shade 4 6
##   sun   9 1</code></pre>
<p>So 6 of the leaves in the shade had rust present and 4 did not. The odds of rust are therefore 6 to 4. Odds are used in the logit transform rather than simple proportions because odds can take values between 0 and infinity, while proportions are bounded to lie between zero and one. Taking the logarithm of the odds leads to an additive model.</p>
<p>There are two factor levels, shade and sun. The default reference when a model is fitted will be the factor that is first in alphabetical order, i.e. shade. So after fitting a model the intercept will be the log of the odds in the shade. The effect of light will be the log odds in the sun minus the log odds in the shade.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">odds_shade&lt;-<span class="dv">6</span><span class="op">/</span><span class="dv">4</span>
odds_sun&lt;-<span class="dv">1</span><span class="op">/</span><span class="dv">9</span>
<span class="kw">log</span>(odds_shade)</code></pre></div>
<pre><code>## [1] 0.4054651</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">log</span>(odds_sun)<span class="op">-</span><span class="kw">log</span>(odds_shade)</code></pre></div>
<pre><code>## [1] -2.60269</code></pre>
<p>We can see that this coincides with the model output.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod&lt;-<span class="kw">glm</span>(<span class="dt">data=</span>d,presence<span class="op">~</span>light,<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
<span class="kw">summary</span>(mod)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = presence ~ light, family = &quot;binomial&quot;, data = d)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.354  -0.459  -0.459   1.011   2.146  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)   0.4055     0.6455   0.628   0.5299  
## lightsun     -2.6027     1.2360  -2.106   0.0352 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 25.898  on 19  degrees of freedom
## Residual deviance: 19.962  on 18  degrees of freedom
## AIC: 23.962
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>If the coeficients are exponentiated then the first coeficient represents the baseline odds and the second coeficient represesnts this value divided by the odds for the “treatment”. As binomial models are often used in epidemiology this explains why we could hear statements such as “eating processed meat increases the odds of contracting bowel cancer by a factor of 2”. This is a literal interpretation of the exponentiated coeficient.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(mod))</code></pre></div>
<pre><code>## (Intercept)    lightsun 
##  1.50000000  0.07407408</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">odds_shade</code></pre></div>
<pre><code>## [1] 1.5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">odds_sun<span class="op">/</span>odds_shade</code></pre></div>
<pre><code>## [1] 0.07407407</code></pre>
<p>To convert the odds into proportions divide the odds by 1 plus the odds.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">odds_shade<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>odds_shade)</code></pre></div>
<pre><code>## [1] 0.6</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">odds_sun<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>odds_sun)</code></pre></div>
<pre><code>## [1] 0.1</code></pre>
<p>So this gives the proportions as estimated by the model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(mod)[<span class="dv">1</span>])<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(<span class="kw">coef</span>(mod)[<span class="dv">1</span>]))</code></pre></div>
<pre><code>## (Intercept) 
##         0.6</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(mod)[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="kw">coef</span>(mod)[<span class="dv">2</span>])<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(<span class="kw">coef</span>(mod)[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="kw">coef</span>(mod)[<span class="dv">2</span>]))</code></pre></div>
<pre><code>## (Intercept) 
##         0.1</code></pre>
</div>
<div id="exercises-5" class="section level2">
<h2><span class="header-section-number">16.8</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>GLMS can also be used when the explanatory variable is a factor. Here is a very simple data set that consists of counts of ragworm in two types of substrate, classified simply into mud and sand. Analyse the data using both a <strong>general</strong> linear model and a <strong>generalised</strong> linear model. Comment on the differences between the two aproaches.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d&lt;-<span class="kw">read.csv</span>(<span class="st">&quot;/home/aqm/course/data/HedisteCounts.csv&quot;</span>)</code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Binomial (prensence/absence) model</li>
</ol>
<p>In some cases the actual numbers of organisms counted can be a poor choice of response variable. If organisms are highly aggregated then presence vs absence is a better choice. Reanalyse the ragworm data, this time using presence as the response.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d<span class="op">$</span>pres&lt;-<span class="dv">1</span><span class="op">*</span>(d<span class="op">$</span>Count<span class="op">&gt;</span><span class="dv">0</span>) ## This sets up a variable consisting of ones and zeros</code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Leafminers and leaf exposure to light</li>
</ol>
<p>The number of leaf miners were counted on 200 leaves exposed to different levels of ambient light, measured as a percentage of full exposure.</p>
<p>Analyse these data using an appropriate GLM.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d&lt;-<span class="kw">read.csv</span>(<span class="st">&quot;/home/aqm/course/data/leafminers.csv&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(d)</code></pre></div>
<p><img src="009_GLMs_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(plotly)</code></pre></div>
<pre><code>## 
## Attaching package: &#39;plotly&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:MASS&#39;:
## 
##     select</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     last_plot</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     filter</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     layout</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">g0&lt;-<span class="kw">ggplot</span>(d,<span class="kw">aes</span>(<span class="dt">x=</span>light,<span class="dt">y=</span>nminers))
glm1&lt;-g0<span class="op">+</span><span class="kw">geom_point</span>()<span class="op">+</span><span class="kw">stat_smooth</span>(<span class="dt">method=</span><span class="st">&quot;glm&quot;</span>,<span class="dt">method.args=</span><span class="kw">list</span>( <span class="dt">family=</span><span class="st">&quot;poisson&quot;</span>), <span class="dt">se=</span><span class="ot">TRUE</span>) <span class="op">+</span><span class="kw">ggtitle</span>(<span class="st">&quot;Poisson regression with log link function&quot;</span>)
<span class="kw">ggplotly</span>(glm1)</code></pre></div>
<div id="79704dbe48c2" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="79704dbe48c2">{"x":{"data":[{"x":[86,87,90,79,91,87,87,86,87,91,94,91,95,90,93,92,89,84,86,87,89,86,91,98,88,89,90,95,84,85,94,89,95,87,82,86,97,89,89,92,90,87,89,97,89,91,91,91,91,87,91,95,88,95,90,87,87,82,89,93,98,90,79,91,90,88,85,84,90,94,96,85,92,88,90,88,91,87,97,85,88,87,84,85,85,95,99,88,90,87,84,96,91,91,96,90,88,88,95,85,96,85,91,88,87,96,86,96,95,90,88,87,87,75,95,93,93,94,84,98,93,92,92,87,82,83,96,91,81,94,94,85,94,91,92,85,97,94,89,87,92,100,87,89,97,89,89,96,91,88,96,82,81,94,90,83,95,87,99,90,82,94,92,88,92,88,94,93,84,93,92,88,96,87,95,91,92,92,87,89,92,96,89,98,92,89,96,86,97,85,88,92,88,92,96,96,87,85,93,87],"y":[6,1,6,0,0,0,5,0,0,0,1,12,2,1,0,11,0,0,0,0,2,3,1,11,1,0,0,1,0,2,2,6,1,7,0,0,1,1,0,0,0,2,0,5,0,2,3,1,2,0,0,1,0,4,0,0,0,0,0,0,2,0,0,0,1,1,2,4,0,6,1,0,1,0,2,9,0,0,1,0,0,1,0,12,0,1,1,0,0,0,0,1,5,15,1,0,5,0,5,0,7,1,6,0,0,1,5,1,1,0,0,12,1,1,1,11,0,1,0,1,2,3,1,10,1,0,1,0,0,3,2,6,1,7,0,0,1,2,0,0,0,3,0,4,1,2,3,2,2,0,1,0,0,4,0,0,1,0,1,0,1,1,0,0,1,1,3,4,0,5,0,0,2,0,3,9,0,0,0,0,0,2,0,13,0,0,1,0,1,0,0,0,5,15,1,1,5,0,4,0],"text":["~light:  86<br />~nminers:  6","~light:  87<br />~nminers:  1","~light:  90<br />~nminers:  6","~light:  79<br />~nminers:  0","~light:  91<br />~nminers:  0","~light:  87<br />~nminers:  0","~light:  87<br />~nminers:  5","~light:  86<br />~nminers:  0","~light:  87<br />~nminers:  0","~light:  91<br />~nminers:  0","~light:  94<br />~nminers:  1","~light:  91<br />~nminers: 12","~light:  95<br />~nminers:  2","~light:  90<br />~nminers:  1","~light:  93<br />~nminers:  0","~light:  92<br />~nminers: 11","~light:  89<br />~nminers:  0","~light:  84<br />~nminers:  0","~light:  86<br />~nminers:  0","~light:  87<br />~nminers:  0","~light:  89<br />~nminers:  2","~light:  86<br />~nminers:  3","~light:  91<br />~nminers:  1","~light:  98<br />~nminers: 11","~light:  88<br />~nminers:  1","~light:  89<br />~nminers:  0","~light:  90<br />~nminers:  0","~light:  95<br />~nminers:  1","~light:  84<br />~nminers:  0","~light:  85<br />~nminers:  2","~light:  94<br />~nminers:  2","~light:  89<br />~nminers:  6","~light:  95<br />~nminers:  1","~light:  87<br />~nminers:  7","~light:  82<br />~nminers:  0","~light:  86<br />~nminers:  0","~light:  97<br />~nminers:  1","~light:  89<br />~nminers:  1","~light:  89<br />~nminers:  0","~light:  92<br />~nminers:  0","~light:  90<br />~nminers:  0","~light:  87<br />~nminers:  2","~light:  89<br />~nminers:  0","~light:  97<br />~nminers:  5","~light:  89<br />~nminers:  0","~light:  91<br />~nminers:  2","~light:  91<br />~nminers:  3","~light:  91<br />~nminers:  1","~light:  91<br />~nminers:  2","~light:  87<br />~nminers:  0","~light:  91<br />~nminers:  0","~light:  95<br />~nminers:  1","~light:  88<br />~nminers:  0","~light:  95<br />~nminers:  4","~light:  90<br />~nminers:  0","~light:  87<br />~nminers:  0","~light:  87<br />~nminers:  0","~light:  82<br />~nminers:  0","~light:  89<br />~nminers:  0","~light:  93<br />~nminers:  0","~light:  98<br />~nminers:  2","~light:  90<br />~nminers:  0","~light:  79<br />~nminers:  0","~light:  91<br />~nminers:  0","~light:  90<br />~nminers:  1","~light:  88<br />~nminers:  1","~light:  85<br />~nminers:  2","~light:  84<br />~nminers:  4","~light:  90<br />~nminers:  0","~light:  94<br />~nminers:  6","~light:  96<br />~nminers:  1","~light:  85<br />~nminers:  0","~light:  92<br />~nminers:  1","~light:  88<br />~nminers:  0","~light:  90<br />~nminers:  2","~light:  88<br />~nminers:  9","~light:  91<br />~nminers:  0","~light:  87<br />~nminers:  0","~light:  97<br />~nminers:  1","~light:  85<br />~nminers:  0","~light:  88<br />~nminers:  0","~light:  87<br />~nminers:  1","~light:  84<br />~nminers:  0","~light:  85<br />~nminers: 12","~light:  85<br />~nminers:  0","~light:  95<br />~nminers:  1","~light:  99<br />~nminers:  1","~light:  88<br />~nminers:  0","~light:  90<br />~nminers:  0","~light:  87<br />~nminers:  0","~light:  84<br />~nminers:  0","~light:  96<br />~nminers:  1","~light:  91<br />~nminers:  5","~light:  91<br />~nminers: 15","~light:  96<br />~nminers:  1","~light:  90<br />~nminers:  0","~light:  88<br />~nminers:  5","~light:  88<br />~nminers:  0","~light:  95<br />~nminers:  5","~light:  85<br />~nminers:  0","~light:  96<br />~nminers:  7","~light:  85<br />~nminers:  1","~light:  91<br />~nminers:  6","~light:  88<br />~nminers:  0","~light:  87<br />~nminers:  0","~light:  96<br />~nminers:  1","~light:  86<br />~nminers:  5","~light:  96<br />~nminers:  1","~light:  95<br />~nminers:  1","~light:  90<br />~nminers:  0","~light:  88<br />~nminers:  0","~light:  87<br />~nminers: 12","~light:  87<br />~nminers:  1","~light:  75<br />~nminers:  1","~light:  95<br />~nminers:  1","~light:  93<br />~nminers: 11","~light:  93<br />~nminers:  0","~light:  94<br />~nminers:  1","~light:  84<br />~nminers:  0","~light:  98<br />~nminers:  1","~light:  93<br />~nminers:  2","~light:  92<br />~nminers:  3","~light:  92<br />~nminers:  1","~light:  87<br />~nminers: 10","~light:  82<br />~nminers:  1","~light:  83<br />~nminers:  0","~light:  96<br />~nminers:  1","~light:  91<br />~nminers:  0","~light:  81<br />~nminers:  0","~light:  94<br />~nminers:  3","~light:  94<br />~nminers:  2","~light:  85<br />~nminers:  6","~light:  94<br />~nminers:  1","~light:  91<br />~nminers:  7","~light:  92<br />~nminers:  0","~light:  85<br />~nminers:  0","~light:  97<br />~nminers:  1","~light:  94<br />~nminers:  2","~light:  89<br />~nminers:  0","~light:  87<br />~nminers:  0","~light:  92<br />~nminers:  0","~light: 100<br />~nminers:  3","~light:  87<br />~nminers:  0","~light:  89<br />~nminers:  4","~light:  97<br />~nminers:  1","~light:  89<br />~nminers:  2","~light:  89<br />~nminers:  3","~light:  96<br />~nminers:  2","~light:  91<br />~nminers:  2","~light:  88<br />~nminers:  0","~light:  96<br />~nminers:  1","~light:  82<br />~nminers:  0","~light:  81<br />~nminers:  0","~light:  94<br />~nminers:  4","~light:  90<br />~nminers:  0","~light:  83<br />~nminers:  0","~light:  95<br />~nminers:  1","~light:  87<br />~nminers:  0","~light:  99<br />~nminers:  1","~light:  90<br />~nminers:  0","~light:  82<br />~nminers:  1","~light:  94<br />~nminers:  1","~light:  92<br />~nminers:  0","~light:  88<br />~nminers:  0","~light:  92<br />~nminers:  1","~light:  88<br />~nminers:  1","~light:  94<br />~nminers:  3","~light:  93<br />~nminers:  4","~light:  84<br />~nminers:  0","~light:  93<br />~nminers:  5","~light:  92<br />~nminers:  0","~light:  88<br />~nminers:  0","~light:  96<br />~nminers:  2","~light:  87<br />~nminers:  0","~light:  95<br />~nminers:  3","~light:  91<br />~nminers:  9","~light:  92<br />~nminers:  0","~light:  92<br />~nminers:  0","~light:  87<br />~nminers:  0","~light:  89<br />~nminers:  0","~light:  92<br />~nminers:  0","~light:  96<br />~nminers:  2","~light:  89<br />~nminers:  0","~light:  98<br />~nminers: 13","~light:  92<br />~nminers:  0","~light:  89<br />~nminers:  0","~light:  96<br />~nminers:  1","~light:  86<br />~nminers:  0","~light:  97<br />~nminers:  1","~light:  85<br />~nminers:  0","~light:  88<br />~nminers:  0","~light:  92<br />~nminers:  0","~light:  88<br />~nminers:  5","~light:  92<br />~nminers: 15","~light:  96<br />~nminers:  1","~light:  96<br />~nminers:  1","~light:  87<br />~nminers:  5","~light:  85<br />~nminers:  0","~light:  93<br />~nminers:  4","~light:  87<br />~nminers:  0"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(0,0,0,1)","opacity":1,"size":5.66929133858268,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[75,75.3164556962025,75.6329113924051,75.9493670886076,76.2658227848101,76.5822784810127,76.8987341772152,77.2151898734177,77.5316455696203,77.8481012658228,78.1645569620253,78.4810126582279,78.7974683544304,79.1139240506329,79.4303797468354,79.746835443038,80.0632911392405,80.379746835443,80.6962025316456,81.0126582278481,81.3291139240506,81.6455696202532,81.9620253164557,82.2784810126582,82.5949367088608,82.9113924050633,83.2278481012658,83.5443037974684,83.8607594936709,84.1772151898734,84.4936708860759,84.8101265822785,85.126582278481,85.4430379746835,85.7594936708861,86.0759493670886,86.3924050632911,86.7088607594937,87.0253164556962,87.3417721518987,87.6582278481013,87.9746835443038,88.2911392405063,88.6075949367089,88.9240506329114,89.2405063291139,89.5569620253165,89.873417721519,90.1898734177215,90.5063291139241,90.8227848101266,91.1392405063291,91.4556962025316,91.7721518987342,92.0886075949367,92.4050632911392,92.7215189873418,93.0379746835443,93.3544303797468,93.6708860759494,93.9873417721519,94.3037974683544,94.620253164557,94.9367088607595,95.253164556962,95.5696202531646,95.8860759493671,96.2025316455696,96.5189873417721,96.8354430379747,97.1518987341772,97.4683544303797,97.7848101265823,98.1012658227848,98.4177215189873,98.7341772151899,99.0506329113924,99.3670886075949,99.6835443037975,100],"y":[0.663802487182636,0.677833796192177,0.69216169588392,0.706792455525595,0.721732476903314,0.736988297122718,0.752566591469329,0.768474176329369,0.784718012172307,0.801305206596472,0.818243017439014,0.835538855951634,0.853200290043413,0.871235047592213,0.889651019826051,0.908456264775966,0.927659010801859,0.947267660192871,0.967290792843854,0.98773717000957,1.00861573813822,1.02993563278606,1.05170618261466,1.07393691347278,1.09663755256446,1.11981803270518,1.14348849666808,1.16765930162198,1.19234102366321,1.21754446244329,1.24328064589434,1.26956083505448,1.2963965289951,1.32379946985245,1.3517816479654,1.38035530712196,1.40953294991656,1.43932734322074,1.46975152376927,1.50081880386456,1.53254277720146,1.56493732481535,1.59801662115581,1.63179514028879,1.66628766222982,1.70150927941111,1.73747540328531,1.77420177106897,1.81170445262836,1.84999985751104,1.88910474212591,1.92903621707512,1.96981175464091,2.01144919643071,2.05396676118389,2.09738305274347,2.14171706819635,2.18698820618563,2.23321627539859,2.28042150323413,2.3286245446534,2.37784649121751,2.42810888031632,2.47943370459217,2.53184342156305,2.58536096344889,2.64000974720582,2.69581368477234,2.75279719353221,2.81098520699835,2.87040318572279,2.93107712843696,2.99303358342774,3.05629966015374,3.12090304110729,3.18687199392704,3.25423538376674,3.32302268592526,3.39326399874382,3.46499005677563],"text":["~light:  75.00000<br />~nminers: 0.6638025","~light:  75.31646<br />~nminers: 0.6778338","~light:  75.63291<br />~nminers: 0.6921617","~light:  75.94937<br />~nminers: 0.7067925","~light:  76.26582<br />~nminers: 0.7217325","~light:  76.58228<br />~nminers: 0.7369883","~light:  76.89873<br />~nminers: 0.7525666","~light:  77.21519<br />~nminers: 0.7684742","~light:  77.53165<br />~nminers: 0.7847180","~light:  77.84810<br />~nminers: 0.8013052","~light:  78.16456<br />~nminers: 0.8182430","~light:  78.48101<br />~nminers: 0.8355389","~light:  78.79747<br />~nminers: 0.8532003","~light:  79.11392<br />~nminers: 0.8712350","~light:  79.43038<br />~nminers: 0.8896510","~light:  79.74684<br />~nminers: 0.9084563","~light:  80.06329<br />~nminers: 0.9276590","~light:  80.37975<br />~nminers: 0.9472677","~light:  80.69620<br />~nminers: 0.9672908","~light:  81.01266<br />~nminers: 0.9877372","~light:  81.32911<br />~nminers: 1.0086157","~light:  81.64557<br />~nminers: 1.0299356","~light:  81.96203<br />~nminers: 1.0517062","~light:  82.27848<br />~nminers: 1.0739369","~light:  82.59494<br />~nminers: 1.0966376","~light:  82.91139<br />~nminers: 1.1198180","~light:  83.22785<br />~nminers: 1.1434885","~light:  83.54430<br />~nminers: 1.1676593","~light:  83.86076<br />~nminers: 1.1923410","~light:  84.17722<br />~nminers: 1.2175445","~light:  84.49367<br />~nminers: 1.2432806","~light:  84.81013<br />~nminers: 1.2695608","~light:  85.12658<br />~nminers: 1.2963965","~light:  85.44304<br />~nminers: 1.3237995","~light:  85.75949<br />~nminers: 1.3517816","~light:  86.07595<br />~nminers: 1.3803553","~light:  86.39241<br />~nminers: 1.4095329","~light:  86.70886<br />~nminers: 1.4393273","~light:  87.02532<br />~nminers: 1.4697515","~light:  87.34177<br />~nminers: 1.5008188","~light:  87.65823<br />~nminers: 1.5325428","~light:  87.97468<br />~nminers: 1.5649373","~light:  88.29114<br />~nminers: 1.5980166","~light:  88.60759<br />~nminers: 1.6317951","~light:  88.92405<br />~nminers: 1.6662877","~light:  89.24051<br />~nminers: 1.7015093","~light:  89.55696<br />~nminers: 1.7374754","~light:  89.87342<br />~nminers: 1.7742018","~light:  90.18987<br />~nminers: 1.8117045","~light:  90.50633<br />~nminers: 1.8499999","~light:  90.82278<br />~nminers: 1.8891047","~light:  91.13924<br />~nminers: 1.9290362","~light:  91.45570<br />~nminers: 1.9698118","~light:  91.77215<br />~nminers: 2.0114492","~light:  92.08861<br />~nminers: 2.0539668","~light:  92.40506<br />~nminers: 2.0973831","~light:  92.72152<br />~nminers: 2.1417171","~light:  93.03797<br />~nminers: 2.1869882","~light:  93.35443<br />~nminers: 2.2332163","~light:  93.67089<br />~nminers: 2.2804215","~light:  93.98734<br />~nminers: 2.3286245","~light:  94.30380<br />~nminers: 2.3778465","~light:  94.62025<br />~nminers: 2.4281089","~light:  94.93671<br />~nminers: 2.4794337","~light:  95.25316<br />~nminers: 2.5318434","~light:  95.56962<br />~nminers: 2.5853610","~light:  95.88608<br />~nminers: 2.6400097","~light:  96.20253<br />~nminers: 2.6958137","~light:  96.51899<br />~nminers: 2.7527972","~light:  96.83544<br />~nminers: 2.8109852","~light:  97.15190<br />~nminers: 2.8704032","~light:  97.46835<br />~nminers: 2.9310771","~light:  97.78481<br />~nminers: 2.9930336","~light:  98.10127<br />~nminers: 3.0562997","~light:  98.41772<br />~nminers: 3.1209030","~light:  98.73418<br />~nminers: 3.1868720","~light:  99.05063<br />~nminers: 3.2542354","~light:  99.36709<br />~nminers: 3.3230227","~light:  99.68354<br />~nminers: 3.3932640","~light: 100.00000<br />~nminers: 3.4649901"],"type":"scatter","mode":"lines","name":"fitted values","line":{"width":3.77952755905512,"color":"rgba(51,102,255,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[75,75.3164556962025,75.6329113924051,75.9493670886076,76.2658227848101,76.5822784810127,76.8987341772152,77.2151898734177,77.5316455696203,77.8481012658228,78.1645569620253,78.4810126582279,78.7974683544304,79.1139240506329,79.4303797468354,79.746835443038,80.0632911392405,80.379746835443,80.6962025316456,81.0126582278481,81.3291139240506,81.6455696202532,81.9620253164557,82.2784810126582,82.5949367088608,82.9113924050633,83.2278481012658,83.5443037974684,83.8607594936709,84.1772151898734,84.4936708860759,84.8101265822785,85.126582278481,85.4430379746835,85.7594936708861,86.0759493670886,86.3924050632911,86.7088607594937,87.0253164556962,87.3417721518987,87.6582278481013,87.9746835443038,88.2911392405063,88.6075949367089,88.9240506329114,89.2405063291139,89.5569620253165,89.873417721519,90.1898734177215,90.5063291139241,90.8227848101266,91.1392405063291,91.4556962025316,91.7721518987342,92.0886075949367,92.4050632911392,92.7215189873418,93.0379746835443,93.3544303797468,93.6708860759494,93.9873417721519,94.3037974683544,94.620253164557,94.9367088607595,95.253164556962,95.5696202531646,95.8860759493671,96.2025316455696,96.5189873417721,96.8354430379747,97.1518987341772,97.4683544303797,97.7848101265823,98.1012658227848,98.4177215189873,98.7341772151899,99.0506329113924,99.3670886075949,99.6835443037975,100,100,100,99.6835443037975,99.3670886075949,99.0506329113924,98.7341772151899,98.4177215189873,98.1012658227848,97.7848101265823,97.4683544303797,97.1518987341772,96.8354430379747,96.5189873417721,96.2025316455696,95.8860759493671,95.5696202531646,95.253164556962,94.9367088607595,94.620253164557,94.3037974683544,93.9873417721519,93.6708860759494,93.3544303797468,93.0379746835443,92.7215189873418,92.4050632911392,92.0886075949367,91.7721518987342,91.4556962025316,91.1392405063291,90.8227848101266,90.5063291139241,90.1898734177215,89.873417721519,89.5569620253165,89.2405063291139,88.9240506329114,88.6075949367089,88.2911392405063,87.9746835443038,87.6582278481013,87.3417721518987,87.0253164556962,86.7088607594937,86.3924050632911,86.0759493670886,85.7594936708861,85.4430379746835,85.126582278481,84.8101265822785,84.4936708860759,84.1772151898734,83.8607594936709,83.5443037974684,83.2278481012658,82.9113924050633,82.5949367088608,82.2784810126582,81.9620253164557,81.6455696202532,81.3291139240506,81.0126582278481,80.6962025316456,80.379746835443,80.0632911392405,79.746835443038,79.4303797468354,79.1139240506329,78.7974683544304,78.4810126582279,78.1645569620253,77.8481012658228,77.5316455696203,77.2151898734177,76.8987341772152,76.5822784810127,76.2658227848101,75.9493670886076,75.6329113924051,75.3164556962025,75,75],"y":[0.446590097962592,0.459327897361429,0.472424413380346,0.485889343197164,0.49973260477217,0.513964336884264,0.528594898379626,0.543634866498608,0.55909503412507,0.574986405777243,0.591320192129689,0.608107802821362,0.625360837264021,0.64309107311744,0.661310452041304,0.680031062267227,0.699265117455585,0.719024931209147,0.739322886505662,0.760171399182135,0.781582874450512,0.80356965524443,0.826143960984793,0.849317815103915,0.873102959378767,0.897510752789395,0.922552052235319,0.948237072010134,0.974575218455736,1.00157489570386,1.02924327788658,1.0575860427012,1.08660706081952,1.11630803544991,1.14668808656937,1.17774327520201,1.20946606500679,1.24184472186658,1.27486265782101,1.3084977343758,1.3427215528321,1.3774987765364,1.41278655201525,1.44853412173773,1.48468274745743,1.52116608323444,1.55791114111668,1.59483996709991,1.63187207828679,1.6689275996853,1.70593089236165,1.74281431625554,1.77952166970493,1.81601084090304,1.8522553149793,1.88824438170831,1.92398212244697,1.95948544928286,1.99478157460843,2.02990529477928,2.06489640116915,2.09979742543868,2.13465181927996,2.16950258447297,2.2043913143004,2.23935757962829,2.27443858512224,2.30966902544168,2.34508108163303,2.38070451014822,2.41656678855525,2.45269329196559,2.48910748215723,2.52583109741922,2.56288433556891,2.60028602572586,2.63805378657777,2.67620417030259,2.71475279222563,2.75371444684379,2.75371444684379,4.35998587555621,4.24135877054618,4.12617239510743,4.01434117334562,3.9057830581701,3.80041957290695,3.69817586860816,3.5989807976321,3.50276700351769,3.40947102626258,3.31903342068757,3.23139888342019,3.14651638089838,3.06433926637204,2.98482536783378,2.90793702085805,2.83364101037062,2.76190837373171,2.69271400531135,2.62603599235875,2.5618546075954,2.50015089180084,2.44090478739993,2.38409283885122,2.32968556006278,2.27764467561827,2.227920549092,2.18045018207891,2.13515616212202,2.09194683248989,2.05071776237401,2.01135436248121,1.97373528968444,1.93773617592697,1.9032332234007,1.87010630928001,1.83824139170138,1.80753215540422,1.77788094792947,1.74919912397211,1.72140694084423,1.69443314412727,1.66821436244381,1.64269440407105,1.61782352234016,1.59355769470229,1.56985794308587,1.54668971055922,1.52402230062297,1.50182837980682,1.48008354081653,1.45876592159091,1.43785587476985,1.41733568186644,1.39718930661764,1.37740218238436,1.35796102896809,1.3388536947379,1.32006902047558,1.30159672182598,1.28342728767247,1.26555189214114,1.2479623182722,1.23065089168636,1.2136104228227,1.19683415653636,1.18031572802503,1.1640491242064,1.14802864979854,1.13224889746512,1.11670472148061,1.10139121444943,1.08630368667977,1.07143764786965,1.05678879081089,1.04235297685744,1.02812622293959,1.01410468993522,1.00028467223441,0.986662588355829,0.446590097962592],"text":["~light:  75.00000<br />~nminers: 0.6638025","~light:  75.31646<br />~nminers: 0.6778338","~light:  75.63291<br />~nminers: 0.6921617","~light:  75.94937<br />~nminers: 0.7067925","~light:  76.26582<br />~nminers: 0.7217325","~light:  76.58228<br />~nminers: 0.7369883","~light:  76.89873<br />~nminers: 0.7525666","~light:  77.21519<br />~nminers: 0.7684742","~light:  77.53165<br />~nminers: 0.7847180","~light:  77.84810<br />~nminers: 0.8013052","~light:  78.16456<br />~nminers: 0.8182430","~light:  78.48101<br />~nminers: 0.8355389","~light:  78.79747<br />~nminers: 0.8532003","~light:  79.11392<br />~nminers: 0.8712350","~light:  79.43038<br />~nminers: 0.8896510","~light:  79.74684<br />~nminers: 0.9084563","~light:  80.06329<br />~nminers: 0.9276590","~light:  80.37975<br />~nminers: 0.9472677","~light:  80.69620<br />~nminers: 0.9672908","~light:  81.01266<br />~nminers: 0.9877372","~light:  81.32911<br />~nminers: 1.0086157","~light:  81.64557<br />~nminers: 1.0299356","~light:  81.96203<br />~nminers: 1.0517062","~light:  82.27848<br />~nminers: 1.0739369","~light:  82.59494<br />~nminers: 1.0966376","~light:  82.91139<br />~nminers: 1.1198180","~light:  83.22785<br />~nminers: 1.1434885","~light:  83.54430<br />~nminers: 1.1676593","~light:  83.86076<br />~nminers: 1.1923410","~light:  84.17722<br />~nminers: 1.2175445","~light:  84.49367<br />~nminers: 1.2432806","~light:  84.81013<br />~nminers: 1.2695608","~light:  85.12658<br />~nminers: 1.2963965","~light:  85.44304<br />~nminers: 1.3237995","~light:  85.75949<br />~nminers: 1.3517816","~light:  86.07595<br />~nminers: 1.3803553","~light:  86.39241<br />~nminers: 1.4095329","~light:  86.70886<br />~nminers: 1.4393273","~light:  87.02532<br />~nminers: 1.4697515","~light:  87.34177<br />~nminers: 1.5008188","~light:  87.65823<br />~nminers: 1.5325428","~light:  87.97468<br />~nminers: 1.5649373","~light:  88.29114<br />~nminers: 1.5980166","~light:  88.60759<br />~nminers: 1.6317951","~light:  88.92405<br />~nminers: 1.6662877","~light:  89.24051<br />~nminers: 1.7015093","~light:  89.55696<br />~nminers: 1.7374754","~light:  89.87342<br />~nminers: 1.7742018","~light:  90.18987<br />~nminers: 1.8117045","~light:  90.50633<br />~nminers: 1.8499999","~light:  90.82278<br />~nminers: 1.8891047","~light:  91.13924<br />~nminers: 1.9290362","~light:  91.45570<br />~nminers: 1.9698118","~light:  91.77215<br />~nminers: 2.0114492","~light:  92.08861<br />~nminers: 2.0539668","~light:  92.40506<br />~nminers: 2.0973831","~light:  92.72152<br />~nminers: 2.1417171","~light:  93.03797<br />~nminers: 2.1869882","~light:  93.35443<br />~nminers: 2.2332163","~light:  93.67089<br />~nminers: 2.2804215","~light:  93.98734<br />~nminers: 2.3286245","~light:  94.30380<br />~nminers: 2.3778465","~light:  94.62025<br />~nminers: 2.4281089","~light:  94.93671<br />~nminers: 2.4794337","~light:  95.25316<br />~nminers: 2.5318434","~light:  95.56962<br />~nminers: 2.5853610","~light:  95.88608<br />~nminers: 2.6400097","~light:  96.20253<br />~nminers: 2.6958137","~light:  96.51899<br />~nminers: 2.7527972","~light:  96.83544<br />~nminers: 2.8109852","~light:  97.15190<br />~nminers: 2.8704032","~light:  97.46835<br />~nminers: 2.9310771","~light:  97.78481<br />~nminers: 2.9930336","~light:  98.10127<br />~nminers: 3.0562997","~light:  98.41772<br />~nminers: 3.1209030","~light:  98.73418<br />~nminers: 3.1868720","~light:  99.05063<br />~nminers: 3.2542354","~light:  99.36709<br />~nminers: 3.3230227","~light:  99.68354<br />~nminers: 3.3932640","~light: 100.00000<br />~nminers: 3.4649901","~light: 100.00000<br />~nminers: 3.4649901","~light: 100.00000<br />~nminers: 3.4649901","~light:  99.68354<br />~nminers: 3.3932640","~light:  99.36709<br />~nminers: 3.3230227","~light:  99.05063<br />~nminers: 3.2542354","~light:  98.73418<br />~nminers: 3.1868720","~light:  98.41772<br />~nminers: 3.1209030","~light:  98.10127<br />~nminers: 3.0562997","~light:  97.78481<br />~nminers: 2.9930336","~light:  97.46835<br />~nminers: 2.9310771","~light:  97.15190<br />~nminers: 2.8704032","~light:  96.83544<br />~nminers: 2.8109852","~light:  96.51899<br />~nminers: 2.7527972","~light:  96.20253<br />~nminers: 2.6958137","~light:  95.88608<br />~nminers: 2.6400097","~light:  95.56962<br />~nminers: 2.5853610","~light:  95.25316<br />~nminers: 2.5318434","~light:  94.93671<br />~nminers: 2.4794337","~light:  94.62025<br />~nminers: 2.4281089","~light:  94.30380<br />~nminers: 2.3778465","~light:  93.98734<br />~nminers: 2.3286245","~light:  93.67089<br />~nminers: 2.2804215","~light:  93.35443<br />~nminers: 2.2332163","~light:  93.03797<br />~nminers: 2.1869882","~light:  92.72152<br />~nminers: 2.1417171","~light:  92.40506<br />~nminers: 2.0973831","~light:  92.08861<br />~nminers: 2.0539668","~light:  91.77215<br />~nminers: 2.0114492","~light:  91.45570<br />~nminers: 1.9698118","~light:  91.13924<br />~nminers: 1.9290362","~light:  90.82278<br />~nminers: 1.8891047","~light:  90.50633<br />~nminers: 1.8499999","~light:  90.18987<br />~nminers: 1.8117045","~light:  89.87342<br />~nminers: 1.7742018","~light:  89.55696<br />~nminers: 1.7374754","~light:  89.24051<br />~nminers: 1.7015093","~light:  88.92405<br />~nminers: 1.6662877","~light:  88.60759<br />~nminers: 1.6317951","~light:  88.29114<br />~nminers: 1.5980166","~light:  87.97468<br />~nminers: 1.5649373","~light:  87.65823<br />~nminers: 1.5325428","~light:  87.34177<br />~nminers: 1.5008188","~light:  87.02532<br />~nminers: 1.4697515","~light:  86.70886<br />~nminers: 1.4393273","~light:  86.39241<br />~nminers: 1.4095329","~light:  86.07595<br />~nminers: 1.3803553","~light:  85.75949<br />~nminers: 1.3517816","~light:  85.44304<br />~nminers: 1.3237995","~light:  85.12658<br />~nminers: 1.2963965","~light:  84.81013<br />~nminers: 1.2695608","~light:  84.49367<br />~nminers: 1.2432806","~light:  84.17722<br />~nminers: 1.2175445","~light:  83.86076<br />~nminers: 1.1923410","~light:  83.54430<br />~nminers: 1.1676593","~light:  83.22785<br />~nminers: 1.1434885","~light:  82.91139<br />~nminers: 1.1198180","~light:  82.59494<br />~nminers: 1.0966376","~light:  82.27848<br />~nminers: 1.0739369","~light:  81.96203<br />~nminers: 1.0517062","~light:  81.64557<br />~nminers: 1.0299356","~light:  81.32911<br />~nminers: 1.0086157","~light:  81.01266<br />~nminers: 0.9877372","~light:  80.69620<br />~nminers: 0.9672908","~light:  80.37975<br />~nminers: 0.9472677","~light:  80.06329<br />~nminers: 0.9276590","~light:  79.74684<br />~nminers: 0.9084563","~light:  79.43038<br />~nminers: 0.8896510","~light:  79.11392<br />~nminers: 0.8712350","~light:  78.79747<br />~nminers: 0.8532003","~light:  78.48101<br />~nminers: 0.8355389","~light:  78.16456<br />~nminers: 0.8182430","~light:  77.84810<br />~nminers: 0.8013052","~light:  77.53165<br />~nminers: 0.7847180","~light:  77.21519<br />~nminers: 0.7684742","~light:  76.89873<br />~nminers: 0.7525666","~light:  76.58228<br />~nminers: 0.7369883","~light:  76.26582<br />~nminers: 0.7217325","~light:  75.94937<br />~nminers: 0.7067925","~light:  75.63291<br />~nminers: 0.6921617","~light:  75.31646<br />~nminers: 0.6778338","~light:  75.00000<br />~nminers: 0.6638025","~light:  75.00000<br />~nminers: 0.6638025"],"type":"scatter","mode":"lines","line":{"width":3.77952755905512,"color":"transparent","dash":"solid"},"fill":"toself","fillcolor":"rgba(153,153,153,0.4)","hoveron":"points","hoverinfo":"x+y","showlegend":false,"xaxis":"x","yaxis":"y","frame":null}],"layout":{"margin":{"t":43.7625570776256,"r":7.30593607305936,"b":40.1826484018265,"l":37.2602739726027},"plot_bgcolor":"rgba(235,235,235,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"title":"Poisson regression with log link function","titlefont":{"color":"rgba(0,0,0,1)","family":"","size":17.5342465753425},"xaxis":{"domain":[0,1],"type":"linear","autorange":false,"range":[73.75,101.25],"tickmode":"array","ticktext":["75","80","85","90","95","100"],"tickvals":[75,80,85,90,95,100],"categoryorder":"array","categoryarray":["75","80","85","90","95","100"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":null,"gridwidth":0,"zeroline":false,"anchor":"y","title":"light","titlefont":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"type":"linear","autorange":false,"range":[-0.75,15.75],"tickmode":"array","ticktext":["0","5","10","15"],"tickvals":[0,5,10,15],"categoryorder":"array","categoryarray":["0","5","10","15"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":null,"gridwidth":0,"zeroline":false,"anchor":"x","title":"nminers","titlefont":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":[{"name":"Collaborate","icon":{"width":1000,"ascent":500,"descent":-50,"path":"M487 375c7-10 9-23 5-36l-79-259c-3-12-11-23-22-31-11-8-22-12-35-12l-263 0c-15 0-29 5-43 15-13 10-23 23-28 37-5 13-5 25-1 37 0 0 0 3 1 7 1 5 1 8 1 11 0 2 0 4-1 6 0 3-1 5-1 6 1 2 2 4 3 6 1 2 2 4 4 6 2 3 4 5 5 7 5 7 9 16 13 26 4 10 7 19 9 26 0 2 0 5 0 9-1 4-1 6 0 8 0 2 2 5 4 8 3 3 5 5 5 7 4 6 8 15 12 26 4 11 7 19 7 26 1 1 0 4 0 9-1 4-1 7 0 8 1 2 3 5 6 8 4 4 6 6 6 7 4 5 8 13 13 24 4 11 7 20 7 28 1 1 0 4 0 7-1 3-1 6-1 7 0 2 1 4 3 6 1 1 3 4 5 6 2 3 3 5 5 6 1 2 3 5 4 9 2 3 3 7 5 10 1 3 2 6 4 10 2 4 4 7 6 9 2 3 4 5 7 7 3 2 7 3 11 3 3 0 8 0 13-1l0-1c7 2 12 2 14 2l218 0c14 0 25-5 32-16 8-10 10-23 6-37l-79-259c-7-22-13-37-20-43-7-7-19-10-37-10l-248 0c-5 0-9-2-11-5-2-3-2-7 0-12 4-13 18-20 41-20l264 0c5 0 10 2 16 5 5 3 8 6 10 11l85 282c2 5 2 10 2 17 7-3 13-7 17-13z m-304 0c-1-3-1-5 0-7 1-1 3-2 6-2l174 0c2 0 4 1 7 2 2 2 4 4 5 7l6 18c0 3 0 5-1 7-1 1-3 2-6 2l-173 0c-3 0-5-1-8-2-2-2-4-4-4-7z m-24-73c-1-3-1-5 0-7 2-2 3-2 6-2l174 0c2 0 5 0 7 2 3 2 4 4 5 7l6 18c1 2 0 5-1 6-1 2-3 3-5 3l-174 0c-3 0-5-1-7-3-3-1-4-4-5-6z"},"click":"function(gd) { \n        // is this being viewed in RStudio?\n        if (location.search == '?viewer_pane=1') {\n          alert('To learn about plotly for collaboration, visit:\\n https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html');\n        } else {\n          window.open('https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html', '_blank');\n        }\n      }"}],"cloud":false},"source":"A","attrs":{"797062105061":{"x":{},"y":{},"type":"scatter"},"79703923e66c":{"x":{},"y":{}}},"cur_data":"797062105061","visdat":{"797062105061":["function (y) ","x"],"79703923e66c":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1}},"base_url":"https://plot.ly"},"evals":["config.modeBarButtonsToAdd.0.click"],"jsHooks":{"render":[{"code":"function(el, x) { var ctConfig = crosstalk.var('plotlyCrosstalkOpts').set({\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1}}); }","data":null}]}}</script>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod&lt;-<span class="kw">glm</span>(<span class="dt">data=</span>d,nminers<span class="op">~</span>light,<span class="dt">family=</span><span class="st">&quot;poisson&quot;</span>)
<span class="kw">summary</span>(mod)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = nminers ~ light, family = &quot;poisson&quot;, data = d)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.0888  -1.7275  -1.1676   0.0864   5.9691  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -5.36721    1.09865  -4.885 1.03e-06 ***
## light        0.06610    0.01203   5.496 3.88e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 751.31  on 199  degrees of freedom
## Residual deviance: 720.43  on 198  degrees of freedom
## AIC: 1025.3
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">log</span>(<span class="dv">2</span>)<span class="op">/</span><span class="kw">coef</span>(mod)[<span class="dv">2</span>]</code></pre></div>
<pre><code>##    light 
## 10.48647</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="factorial-designs.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modelling-with-multiple-variables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["AQM_book.pdf", "AQM_book.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
